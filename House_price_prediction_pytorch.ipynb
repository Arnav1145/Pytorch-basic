{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb586c6a-5e97-4bdc-93a4-a7761ababd62",
   "metadata": {},
   "source": [
    "# Kaggle Advance House Price prediction using pytorch - Tabular dataset\n",
    "https://docs.fast.ai/tabular.html<br>\n",
    "https://www.fast.ai/2018/04/29/categorical-embeddings/ <br>\n",
    "https://yashuseth.blog/2018/07/22/pytorch-neural-network-for-tabular-data-with-categorical-embeddings/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067efae6-d3f0-4668-bd47-3ecb2b577c84",
   "metadata": {},
   "source": [
    "Feature Engineering {Cateogrical --- Embedding Layer, Continous Variable}<br>\n",
    "Pythonic Class to create feed forward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3370154-44d1-4fa6-b2e1-cd700d39dfc3",
   "metadata": {},
   "source": [
    "1. Category Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d030fbc5-d2b3-448d-83cb-378b151091eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ddf2e2-aa23-4b25-8a76-fd9aed15894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('houseprice.csv', usecols = [\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50120e96-606d-4b8e-83f8-a703d690b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08fd0f5-de09-4851-8d7c-76e8294dbbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77de00cb-1016-4668-84c7-2b966bab2bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1201 non-null   int64  \n",
      " 1   MSZoning     1201 non-null   object \n",
      " 2   LotFrontage  1201 non-null   float64\n",
      " 3   LotArea      1201 non-null   int64  \n",
      " 4   Street       1201 non-null   object \n",
      " 5   LotShape     1201 non-null   object \n",
      " 6   YearBuilt    1201 non-null   int64  \n",
      " 7   1stFlrSF     1201 non-null   int64  \n",
      " 8   2ndFlrSF     1201 non-null   int64  \n",
      " 9   SalePrice    1201 non-null   int64  \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e42928-5111-4a7d-b8dd-d84e4dbcf283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1             20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2             60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3             70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4             60       RL         84.0    14260   Pave      IR1       2000   \n",
       "...          ...      ...          ...      ...    ...      ...        ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg       1999   \n",
       "1456          20       RL         85.0    13175   Pave      Reg       1978   \n",
       "1457          70       RL         66.0     9042   Pave      Reg       1941   \n",
       "1458          20       RL         68.0     9717   Pave      Reg       1950   \n",
       "1459          20       RL         75.0     9937   Pave      Reg       1965   \n",
       "\n",
       "      1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0          856       854     208500  \n",
       "1         1262         0     181500  \n",
       "2          920       866     223500  \n",
       "3          961       756     140000  \n",
       "4         1145      1053     250000  \n",
       "...        ...       ...        ...  \n",
       "1455       953       694     175000  \n",
       "1456      2073         0     210000  \n",
       "1457      1188      1152     266500  \n",
       "1458      1078         0     142125  \n",
       "1459      1256         0     147500  \n",
       "\n",
       "[1201 rows x 10 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444b348-6a5a-4b51-81f0-9cd901d2f312",
   "metadata": {},
   "source": [
    "1. Cateogrical Features --> Handled by Embedding Layers\n",
    "2. Numerical feataures (no such special handler is required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8b9c69-48de-4de0-9dc9-6a9f68c95112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name MSSubClass and unique values are 15\n",
      "Column name MSZoning and unique values are 5\n",
      "Column name LotFrontage and unique values are 110\n",
      "Column name LotArea and unique values are 869\n",
      "Column name Street and unique values are 2\n",
      "Column name LotShape and unique values are 4\n",
      "Column name YearBuilt and unique values are 112\n",
      "Column name 1stFlrSF and unique values are 678\n",
      "Column name 2ndFlrSF and unique values are 368\n",
      "Column name SalePrice and unique values are 597\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(\"Column name {} and unique values are {}\".format(i, len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e62718-0921-4887-8fd3-8fed9cd01988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3438ffff-8023-495f-93d1-e8f236f861f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a derived features which will be total number of year, i.e.,\n",
    "# difference between present year - year in the table\n",
    "\n",
    "df['Total Years'] = datetime.datetime.now().year - df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aaaabc1-8a43-4eb8-83dc-58e257ec6b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  Total Years  \n",
       "0       856       854     208500           21  \n",
       "1      1262         0     181500           48  \n",
       "2       920       866     223500           23  \n",
       "3       961       756     140000          109  \n",
       "4      1145      1053     250000           24  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ce8398-a6ae-4ab6-947a-fea63097c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"YearBuilt\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcf6b96-05e3-4b19-b860-d91141b1bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  1stFlrSF  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       856   \n",
       "1          20       RL         80.0     9600   Pave      Reg      1262   \n",
       "2          60       RL         68.0    11250   Pave      IR1       920   \n",
       "3          70       RL         60.0     9550   Pave      IR1       961   \n",
       "4          60       RL         84.0    14260   Pave      IR1      1145   \n",
       "\n",
       "   2ndFlrSF  SalePrice  Total Years  \n",
       "0       854     208500           21  \n",
       "1         0     181500           48  \n",
       "2       866     223500           23  \n",
       "3       756     140000          109  \n",
       "4      1053     250000           24  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf6ceaf6-a794-4821-86e6-5dbf0ba1383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', '1stFlrSF', '2ndFlrSF', 'SalePrice', 'Total Years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faead184-55af-47f2-a954-b194641cae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]\n",
    "out_feature = \"SalesPrice\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4428e6-a4c7-4485-9832-5655f505f515",
   "metadata": {},
   "source": [
    "Handling one categorical feature first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5020523-c6f0-407c-800d-78400694dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 5, ..., 6, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoders = {}\n",
    "lbl_encoders[\"MSSubClass\"] = LabelEncoder()\n",
    "lbl_encoders[\"MSSubClass\"].fit_transform(df[\"MSSubClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fda0b7f-e31c-4511-bd9b-e8af2b4fe89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSSubClass': LabelEncoder()}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95957e-da6f-4a4e-bc88-640e0d339b64",
   "metadata": {},
   "source": [
    "#### Doing the smae thing as we done for MSSubClass on all the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ab33d83-c600-4299-8e76-7a0ec75f7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoders = {}\n",
    "for feature in cat_features:\n",
    "    lbl_encoders[feature] = LabelEncoder()\n",
    "    df[feature] = lbl_encoders[feature].fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc49f3d9-5241-4266-806c-6c32ad2d4595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>953</td>\n",
       "      <td>694</td>\n",
       "      <td>175000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>210000</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1188</td>\n",
       "      <td>1152</td>\n",
       "      <td>266500</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>0</td>\n",
       "      <td>142125</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>147500</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n",
       "0              5         3         65.0     8450       1         3       856   \n",
       "1              0         3         80.0     9600       1         3      1262   \n",
       "2              5         3         68.0    11250       1         0       920   \n",
       "3              6         3         60.0     9550       1         0       961   \n",
       "4              5         3         84.0    14260       1         0      1145   \n",
       "...          ...       ...          ...      ...     ...       ...       ...   \n",
       "1455           5         3         62.0     7917       1         3       953   \n",
       "1456           0         3         85.0    13175       1         3      2073   \n",
       "1457           6         3         66.0     9042       1         3      1188   \n",
       "1458           0         3         68.0     9717       1         3      1078   \n",
       "1459           0         3         75.0     9937       1         3      1256   \n",
       "\n",
       "      2ndFlrSF  SalePrice  Total Years  \n",
       "0          854     208500           21  \n",
       "1            0     181500           48  \n",
       "2          866     223500           23  \n",
       "3          756     140000          109  \n",
       "4         1053     250000           24  \n",
       "...        ...        ...          ...  \n",
       "1455       694     175000           25  \n",
       "1456         0     210000           46  \n",
       "1457      1152     266500           83  \n",
       "1458         0     142125           74  \n",
       "1459         0     147500           59  \n",
       "\n",
       "[1201 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71d571-3c3f-4f13-b8be-319b83fe02bb",
   "metadata": {},
   "source": [
    "1. Steps for handling Features ---><br>\n",
    "a). Label Encoding <br>\n",
    "b). take all the catgorical features --> {numpy, torch --> tensors} --> <br>\n",
    "c). Let's take all the continous values <br>\n",
    "d). Continous Variable --> Numpy --> torch --> Tensors <br>\n",
    "e). Using Embedding Layers (only for categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce55aa43-26ba-44ec-b698-636c93aef890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [6, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [0, 3, 1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Stacking and Converting the Tensors\n",
    "import numpy as np\n",
    "cat_features = np.stack([df['MSSubClass'], df['MSZoning'], df['Street'], df['LotShape']], axis = 1)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31474d8-56ac-45c6-bec7-bafe094f62f3",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "<b>Cateogrical features can never be converted into the float as like in other cases, it should be converted in integer as done below</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b83c23c-3a2b-475e-8e5d-5be5345c1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arana\\AppData\\Local\\Temp\\ipykernel_14132\\179690296.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cat_features = torch.tensor(cat_features, dtype = torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert numpy to Tensors\n",
    "import torch\n",
    "cat_features = torch.tensor(cat_features, dtype = torch.int64)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09656003-b029-47d0-86a6-8077c78a7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create continous variable\n",
    "cont_features = []\n",
    "for i in df.columns:\n",
    "    if i in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\",\"SalePrice\"]:\n",
    "        pass\n",
    "    else:\n",
    "        cont_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdb009b1-580a-4cd6-92f0-6193a246c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total Years']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffc11ec3-f857-49e1-af1b-2ff11f68fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    21.],\n",
       "        [   80.,  9600.,  1262.,     0.,    48.],\n",
       "        [   68., 11250.,   920.,   866.,    23.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    83.],\n",
       "        [   68.,  9717.,  1078.,     0.,    74.],\n",
       "        [   75.,  9937.,  1256.,     0.,    59.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Stacking continous variable to a tensor\n",
    "cont_values = np.stack([df[i].values for i in cont_features], axis = 1)\n",
    "cont_values = torch.tensor(cont_values, dtype = torch.float)\n",
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c5edcf-cda5-43e0-8d67-372eec7a4340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a69aca-81e8-4e9d-b8bf-34b5ec851b10",
   "metadata": {},
   "source": [
    "<b>Why Embedding over OneHotEncoding?<br></b>\n",
    "Due to better performance (See Word2Vec for more info)\n",
    "In word2vec the relation between the variables and values in the feature is properly captured due to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95def9a9-1c04-43b5-860a-0b856f39e0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[208500.],\n",
       "        [181500.],\n",
       "        [223500.],\n",
       "        ...,\n",
       "        [266500.],\n",
       "        [142125.],\n",
       "        [147500.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dependent feature\n",
    "y = torch.tensor(df['SalePrice'].values, dtype = torch.float).reshape(-1,1) #reshape important since it converts the 1D tensor in a 2Dimensional tensor\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e309fd00-a767-40d5-aa4a-da803d2c8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1201 non-null   int64  \n",
      " 1   MSZoning     1201 non-null   int32  \n",
      " 2   LotFrontage  1201 non-null   float64\n",
      " 3   LotArea      1201 non-null   int64  \n",
      " 4   Street       1201 non-null   int32  \n",
      " 5   LotShape     1201 non-null   int32  \n",
      " 6   1stFlrSF     1201 non-null   int64  \n",
      " 7   2ndFlrSF     1201 non-null   int64  \n",
      " 8   SalePrice    1201 non-null   int64  \n",
      " 9   Total Years  1201 non-null   int64  \n",
      "dtypes: float64(1), int32(3), int64(6)\n",
      "memory usage: 89.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5366a041-fe35-4ae5-81c4-0452a6a4676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1201, 4]), torch.Size([1201, 5]), torch.Size([1201, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features.shape, cont_values.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d85dbf5-e240-4919-a1e2-b32cf63a0844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21cd4488-c328-4403-9657-9872005d596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['MSSubClass'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d0523-0ab1-4d89-991c-58e5f22fce2a",
   "metadata": {},
   "source": [
    "## Embedding for categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cffc9-1bbd-475c-bb0e-d74efb352c64",
   "metadata": {},
   "source": [
    "We need the length of unique values of each categorical column, since it will tell the embedding layer about its input and based on this what will be the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "547ae624-a392-4141-8106-58434cc3ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dimension = [len(df[col].unique()) for col in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca05d217-480b-4045-b7e4-9a21e447a2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 5, 2, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce1cef-6d1e-43bd-aa68-bd600bb120ed",
   "metadata": {},
   "source": [
    "#### Thumb Rule:<br>\n",
    "Output dimension should be set based on the input dimension(min(50, feature_dimension / 2))\n",
    "\n",
    "here, feature_dimension = no. of unique values in a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75795833-10dc-44db-827d-736a28b3246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = [(x, min(50, (x + 1) // 2)) for x in cat_dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5cbab8f-49b4-4363-8db2-b3812e6cb634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97958eae-1aca-4f65-8a8c-a98315421152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f0074cc-3d58-446e-953a-b8366b5a55fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(15, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "embedded_representation = nn.ModuleList([nn.Embedding(inp, out) for inp,out in embedding_dimension])\n",
    "embedded_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fac552d5-9e08-4d50-b9bd-9d74d0578a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a51ab0cf-2a9d-4f19-9965-f759a609c661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_featuresz = cat_features[:4]\n",
    "cat_featuresz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2af31795-7adf-4686-82af-50e17d4c5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "embedding_val = []\n",
    "for i,e in enumerate(embedded_representation):\n",
    "    embedding_val.append(e(cat_features[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12b4a318-0d11-44db-bb23-0b9da1cf0d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3471, -0.2579,  0.8902,  ...,  1.0906,  1.2262,  1.2660],\n",
       "         [ 1.5751, -0.3561,  0.6400,  ...,  0.4685, -0.1423, -1.4047],\n",
       "         [-0.3471, -0.2579,  0.8902,  ...,  1.0906,  1.2262,  1.2660],\n",
       "         ...,\n",
       "         [ 0.1333, -0.1921, -1.1465,  ..., -0.9317,  0.1480,  0.3066],\n",
       "         [ 1.5751, -0.3561,  0.6400,  ...,  0.4685, -0.1423, -1.4047],\n",
       "         [ 1.5751, -0.3561,  0.6400,  ...,  0.4685, -0.1423, -1.4047]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.2855, -1.5032, -1.0950],\n",
       "         [ 1.2855, -1.5032, -1.0950],\n",
       "         [ 1.2855, -1.5032, -1.0950],\n",
       "         ...,\n",
       "         [ 1.2855, -1.5032, -1.0950],\n",
       "         [ 1.2855, -1.5032, -1.0950],\n",
       "         [ 1.2855, -1.5032, -1.0950]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[0.3029],\n",
       "         [0.3029],\n",
       "         [0.3029],\n",
       "         ...,\n",
       "         [0.3029],\n",
       "         [0.3029],\n",
       "         [0.3029]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.3736, -1.1967],\n",
       "         [ 0.3736, -1.1967],\n",
       "         [-1.8550,  0.7724],\n",
       "         ...,\n",
       "         [ 0.3736, -1.1967],\n",
       "         [ 0.3736, -1.1967],\n",
       "         [ 0.3736, -1.1967]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34f36615-8e42-4ba1-a30f-64a8c593abe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3471, -0.2579,  0.8902,  ...,  0.3029,  0.3736, -1.1967],\n",
       "        [ 1.5751, -0.3561,  0.6400,  ...,  0.3029,  0.3736, -1.1967],\n",
       "        [-0.3471, -0.2579,  0.8902,  ...,  0.3029, -1.8550,  0.7724],\n",
       "        ...,\n",
       "        [ 0.1333, -0.1921, -1.1465,  ...,  0.3029,  0.3736, -1.1967],\n",
       "        [ 1.5751, -0.3561,  0.6400,  ...,  0.3029,  0.3736, -1.1967],\n",
       "        [ 1.5751, -0.3561,  0.6400,  ...,  0.3029,  0.3736, -1.1967]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat(embedding_val, axis = 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e8bfd-4a39-4ff2-86da-b8251e0d2a16",
   "metadata": {},
   "source": [
    "#### Stack vs Cat\n",
    "\n",
    "Stack used in numpy while cat in tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf56ab03-ea7e-43cf-aac3-a69a98410006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implement dropout layer\n",
    "dropout = nn.Dropout(.4) # To avoid Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "639a7dbc-de20-4eae-a74d-17317c0ed172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000,  1.4836,  ...,  0.5048,  0.6226, -0.0000],\n",
       "        [ 0.0000, -0.0000,  1.0667,  ...,  0.0000,  0.6226, -1.9946],\n",
       "        [-0.5786, -0.4298,  0.0000,  ...,  0.5048, -3.0917,  0.0000],\n",
       "        ...,\n",
       "        [ 0.2222, -0.3202, -1.9109,  ...,  0.0000,  0.6226, -0.0000],\n",
       "        [ 0.0000, -0.0000,  1.0667,  ...,  0.0000,  0.6226, -0.0000],\n",
       "        [ 2.6252, -0.0000,  0.0000,  ...,  0.5048,  0.6226, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embedded = dropout(z)\n",
    "final_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bef5c8cb-4957-4101-9089-c633b349e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Feed Forward Neural Network\n",
    "### based on the same above steps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p = 0.5):\n",
    "        '''\n",
    "        embedding_dim = embedding dimension\n",
    "        n_cont\n",
    "        out_sz = output layer\n",
    "        p = dropout ratio\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        layerlist = []\n",
    "        n_emb = sum((out for inp,out in embedding_dim)) #Total dimension\n",
    "        n_in = n_emb + n_cont # Total input\n",
    "\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ccf60c1-b025-47bd-b689-365f13b84784",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "model = FeedForwardNN(embedding_dimension, len(cont_features), 1, [100, 50], p = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5646f9a5-8c12-499c-8c59-495bb027e792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad3268-c443-419e-8701-0dc41e78efbd",
   "metadata": {},
   "source": [
    "#### Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2057aba5-e64b-4ae7-a8f8-344842662314",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss() ## Later convert to RMSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "819987e8-5315-4414-9c5a-701ddbf3e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1200\n",
    "test_size = int(batch_size*0.15)\n",
    "\n",
    "train_categorical = cat_features[:batch_size-test_size]\n",
    "test_categorical = cat_features[batch_size-test_size:batch_size]\n",
    "\n",
    "train_cont = cont_values[:batch_size-test_size]\n",
    "test_cont = cont_values[batch_size-test_size:batch_size]\n",
    "\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5afe22d0-d8a4-4ea4-a4fe-71ec0146bf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 180, 1020, 180, 1020, 180)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "355db5d7-a74c-48c2-9497-0641b0f7ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss : 200496.75\n",
      "Epoch number: 11 and the loss : 200493.46875\n",
      "Epoch number: 21 and the loss : 200489.140625\n",
      "Epoch number: 31 and the loss : 200482.640625\n",
      "Epoch number: 41 and the loss : 200473.25\n",
      "Epoch number: 51 and the loss : 200461.375\n",
      "Epoch number: 61 and the loss : 200446.40625\n",
      "Epoch number: 71 and the loss : 200429.359375\n",
      "Epoch number: 81 and the loss : 200408.0\n",
      "Epoch number: 91 and the loss : 200383.421875\n",
      "Epoch number: 101 and the loss : 200355.3125\n",
      "Epoch number: 111 and the loss : 200322.125\n",
      "Epoch number: 121 and the loss : 200291.4375\n",
      "Epoch number: 131 and the loss : 200252.015625\n",
      "Epoch number: 141 and the loss : 200206.59375\n",
      "Epoch number: 151 and the loss : 200162.234375\n",
      "Epoch number: 161 and the loss : 200112.234375\n",
      "Epoch number: 171 and the loss : 200059.625\n",
      "Epoch number: 181 and the loss : 200005.75\n",
      "Epoch number: 191 and the loss : 199946.40625\n",
      "Epoch number: 201 and the loss : 199881.546875\n",
      "Epoch number: 211 and the loss : 199815.78125\n",
      "Epoch number: 221 and the loss : 199736.96875\n",
      "Epoch number: 231 and the loss : 199668.890625\n",
      "Epoch number: 241 and the loss : 199589.015625\n",
      "Epoch number: 251 and the loss : 199505.34375\n",
      "Epoch number: 261 and the loss : 199410.921875\n",
      "Epoch number: 271 and the loss : 199324.375\n",
      "Epoch number: 281 and the loss : 199243.109375\n",
      "Epoch number: 291 and the loss : 199141.296875\n",
      "Epoch number: 301 and the loss : 199027.046875\n",
      "Epoch number: 311 and the loss : 198931.734375\n",
      "Epoch number: 321 and the loss : 198845.15625\n",
      "Epoch number: 331 and the loss : 198694.65625\n",
      "Epoch number: 341 and the loss : 198602.84375\n",
      "Epoch number: 351 and the loss : 198491.4375\n",
      "Epoch number: 361 and the loss : 198385.015625\n",
      "Epoch number: 371 and the loss : 198244.515625\n",
      "Epoch number: 381 and the loss : 198104.1875\n",
      "Epoch number: 391 and the loss : 198014.296875\n",
      "Epoch number: 401 and the loss : 197883.8125\n",
      "Epoch number: 411 and the loss : 197728.3125\n",
      "Epoch number: 421 and the loss : 197595.25\n",
      "Epoch number: 431 and the loss : 197424.34375\n",
      "Epoch number: 441 and the loss : 197283.25\n",
      "Epoch number: 451 and the loss : 197170.421875\n",
      "Epoch number: 461 and the loss : 196963.328125\n",
      "Epoch number: 471 and the loss : 196877.875\n",
      "Epoch number: 481 and the loss : 196702.671875\n",
      "Epoch number: 491 and the loss : 196502.953125\n",
      "Epoch number: 501 and the loss : 196434.0\n",
      "Epoch number: 511 and the loss : 196209.921875\n",
      "Epoch number: 521 and the loss : 196042.4375\n",
      "Epoch number: 531 and the loss : 195848.359375\n",
      "Epoch number: 541 and the loss : 195662.3125\n",
      "Epoch number: 551 and the loss : 195458.78125\n",
      "Epoch number: 561 and the loss : 195286.515625\n",
      "Epoch number: 571 and the loss : 195070.484375\n",
      "Epoch number: 581 and the loss : 194839.90625\n",
      "Epoch number: 591 and the loss : 194688.28125\n",
      "Epoch number: 601 and the loss : 194522.375\n",
      "Epoch number: 611 and the loss : 194278.734375\n",
      "Epoch number: 621 and the loss : 194119.84375\n",
      "Epoch number: 631 and the loss : 193831.125\n",
      "Epoch number: 641 and the loss : 193681.484375\n",
      "Epoch number: 651 and the loss : 193479.234375\n",
      "Epoch number: 661 and the loss : 193224.515625\n",
      "Epoch number: 671 and the loss : 193059.15625\n",
      "Epoch number: 681 and the loss : 192778.53125\n",
      "Epoch number: 691 and the loss : 192494.484375\n",
      "Epoch number: 701 and the loss : 192294.953125\n",
      "Epoch number: 711 and the loss : 192207.109375\n",
      "Epoch number: 721 and the loss : 191971.171875\n",
      "Epoch number: 731 and the loss : 191624.171875\n",
      "Epoch number: 741 and the loss : 191489.65625\n",
      "Epoch number: 751 and the loss : 191245.296875\n",
      "Epoch number: 761 and the loss : 191055.8125\n",
      "Epoch number: 771 and the loss : 190739.40625\n",
      "Epoch number: 781 and the loss : 190472.171875\n",
      "Epoch number: 791 and the loss : 190286.96875\n",
      "Epoch number: 801 and the loss : 189873.09375\n",
      "Epoch number: 811 and the loss : 189751.203125\n",
      "Epoch number: 821 and the loss : 189657.390625\n",
      "Epoch number: 831 and the loss : 189290.4375\n",
      "Epoch number: 841 and the loss : 188938.546875\n",
      "Epoch number: 851 and the loss : 188830.0625\n",
      "Epoch number: 861 and the loss : 188383.671875\n",
      "Epoch number: 871 and the loss : 188172.21875\n",
      "Epoch number: 881 and the loss : 187893.53125\n",
      "Epoch number: 891 and the loss : 187490.484375\n",
      "Epoch number: 901 and the loss : 187432.515625\n",
      "Epoch number: 911 and the loss : 187237.625\n",
      "Epoch number: 921 and the loss : 186800.078125\n",
      "Epoch number: 931 and the loss : 186372.28125\n",
      "Epoch number: 941 and the loss : 186154.15625\n",
      "Epoch number: 951 and the loss : 185955.0625\n",
      "Epoch number: 961 and the loss : 185642.8125\n",
      "Epoch number: 971 and the loss : 185298.515625\n",
      "Epoch number: 981 and the loss : 185071.5\n",
      "Epoch number: 991 and the loss : 184808.234375\n",
      "Epoch number: 1001 and the loss : 184321.78125\n",
      "Epoch number: 1011 and the loss : 184019.71875\n",
      "Epoch number: 1021 and the loss : 183799.75\n",
      "Epoch number: 1031 and the loss : 183371.375\n",
      "Epoch number: 1041 and the loss : 183232.0625\n",
      "Epoch number: 1051 and the loss : 182921.15625\n",
      "Epoch number: 1061 and the loss : 182547.296875\n",
      "Epoch number: 1071 and the loss : 182325.125\n",
      "Epoch number: 1081 and the loss : 181940.453125\n",
      "Epoch number: 1091 and the loss : 181631.34375\n",
      "Epoch number: 1101 and the loss : 181300.203125\n",
      "Epoch number: 1111 and the loss : 180783.546875\n",
      "Epoch number: 1121 and the loss : 180519.609375\n",
      "Epoch number: 1131 and the loss : 180433.828125\n",
      "Epoch number: 1141 and the loss : 179926.875\n",
      "Epoch number: 1151 and the loss : 179530.9375\n",
      "Epoch number: 1161 and the loss : 179355.890625\n",
      "Epoch number: 1171 and the loss : 179029.609375\n",
      "Epoch number: 1181 and the loss : 178513.3125\n",
      "Epoch number: 1191 and the loss : 178229.875\n",
      "Epoch number: 1201 and the loss : 178234.625\n",
      "Epoch number: 1211 and the loss : 177486.375\n",
      "Epoch number: 1221 and the loss : 177655.953125\n",
      "Epoch number: 1231 and the loss : 176581.453125\n",
      "Epoch number: 1241 and the loss : 176330.671875\n",
      "Epoch number: 1251 and the loss : 175532.015625\n",
      "Epoch number: 1261 and the loss : 175574.15625\n",
      "Epoch number: 1271 and the loss : 175466.078125\n",
      "Epoch number: 1281 and the loss : 174937.890625\n",
      "Epoch number: 1291 and the loss : 174487.328125\n",
      "Epoch number: 1301 and the loss : 174215.1875\n",
      "Epoch number: 1311 and the loss : 173672.453125\n",
      "Epoch number: 1321 and the loss : 173090.1875\n",
      "Epoch number: 1331 and the loss : 173415.96875\n",
      "Epoch number: 1341 and the loss : 172613.15625\n",
      "Epoch number: 1351 and the loss : 172270.53125\n",
      "Epoch number: 1361 and the loss : 172004.546875\n",
      "Epoch number: 1371 and the loss : 171864.03125\n",
      "Epoch number: 1381 and the loss : 171580.796875\n",
      "Epoch number: 1391 and the loss : 170400.578125\n",
      "Epoch number: 1401 and the loss : 170522.921875\n",
      "Epoch number: 1411 and the loss : 169677.21875\n",
      "Epoch number: 1421 and the loss : 169875.625\n",
      "Epoch number: 1431 and the loss : 169497.1875\n",
      "Epoch number: 1441 and the loss : 168691.53125\n",
      "Epoch number: 1451 and the loss : 168615.53125\n",
      "Epoch number: 1461 and the loss : 168015.1875\n",
      "Epoch number: 1471 and the loss : 167822.875\n",
      "Epoch number: 1481 and the loss : 167315.578125\n",
      "Epoch number: 1491 and the loss : 166578.625\n",
      "Epoch number: 1501 and the loss : 166371.375\n",
      "Epoch number: 1511 and the loss : 165610.390625\n",
      "Epoch number: 1521 and the loss : 165828.484375\n",
      "Epoch number: 1531 and the loss : 165316.265625\n",
      "Epoch number: 1541 and the loss : 164551.359375\n",
      "Epoch number: 1551 and the loss : 164501.109375\n",
      "Epoch number: 1561 and the loss : 163893.9375\n",
      "Epoch number: 1571 and the loss : 163463.75\n",
      "Epoch number: 1581 and the loss : 163066.265625\n",
      "Epoch number: 1591 and the loss : 163003.203125\n",
      "Epoch number: 1601 and the loss : 162399.484375\n",
      "Epoch number: 1611 and the loss : 161721.921875\n",
      "Epoch number: 1621 and the loss : 160829.453125\n",
      "Epoch number: 1631 and the loss : 160855.21875\n",
      "Epoch number: 1641 and the loss : 160716.265625\n",
      "Epoch number: 1651 and the loss : 160189.125\n",
      "Epoch number: 1661 and the loss : 160180.765625\n",
      "Epoch number: 1671 and the loss : 159061.34375\n",
      "Epoch number: 1681 and the loss : 158393.578125\n",
      "Epoch number: 1691 and the loss : 158363.375\n",
      "Epoch number: 1701 and the loss : 157669.0625\n",
      "Epoch number: 1711 and the loss : 157363.0\n",
      "Epoch number: 1721 and the loss : 157152.90625\n",
      "Epoch number: 1731 and the loss : 156978.59375\n",
      "Epoch number: 1741 and the loss : 156230.65625\n",
      "Epoch number: 1751 and the loss : 156154.640625\n",
      "Epoch number: 1761 and the loss : 154736.046875\n",
      "Epoch number: 1771 and the loss : 154344.953125\n",
      "Epoch number: 1781 and the loss : 154094.171875\n",
      "Epoch number: 1791 and the loss : 153724.421875\n",
      "Epoch number: 1801 and the loss : 153111.71875\n",
      "Epoch number: 1811 and the loss : 152854.265625\n",
      "Epoch number: 1821 and the loss : 152275.0625\n",
      "Epoch number: 1831 and the loss : 152468.328125\n",
      "Epoch number: 1841 and the loss : 151605.515625\n",
      "Epoch number: 1851 and the loss : 150600.703125\n",
      "Epoch number: 1861 and the loss : 150842.125\n",
      "Epoch number: 1871 and the loss : 150089.90625\n",
      "Epoch number: 1881 and the loss : 149276.453125\n",
      "Epoch number: 1891 and the loss : 148511.75\n",
      "Epoch number: 1901 and the loss : 148668.65625\n",
      "Epoch number: 1911 and the loss : 149021.21875\n",
      "Epoch number: 1921 and the loss : 147748.84375\n",
      "Epoch number: 1931 and the loss : 147386.265625\n",
      "Epoch number: 1941 and the loss : 146683.375\n",
      "Epoch number: 1951 and the loss : 146552.984375\n",
      "Epoch number: 1961 and the loss : 145988.3125\n",
      "Epoch number: 1971 and the loss : 145611.59375\n",
      "Epoch number: 1981 and the loss : 145835.984375\n",
      "Epoch number: 1991 and the loss : 144527.34375\n",
      "Epoch number: 2001 and the loss : 144112.25\n",
      "Epoch number: 2011 and the loss : 143002.03125\n",
      "Epoch number: 2021 and the loss : 143016.59375\n",
      "Epoch number: 2031 and the loss : 142595.9375\n",
      "Epoch number: 2041 and the loss : 142012.671875\n",
      "Epoch number: 2051 and the loss : 141045.421875\n",
      "Epoch number: 2061 and the loss : 141026.515625\n",
      "Epoch number: 2071 and the loss : 141011.484375\n",
      "Epoch number: 2081 and the loss : 139754.25\n",
      "Epoch number: 2091 and the loss : 139737.5625\n",
      "Epoch number: 2101 and the loss : 139390.359375\n",
      "Epoch number: 2111 and the loss : 138647.46875\n",
      "Epoch number: 2121 and the loss : 137778.09375\n",
      "Epoch number: 2131 and the loss : 137911.3125\n",
      "Epoch number: 2141 and the loss : 137267.921875\n",
      "Epoch number: 2151 and the loss : 136726.40625\n",
      "Epoch number: 2161 and the loss : 136503.125\n",
      "Epoch number: 2171 and the loss : 137547.46875\n",
      "Epoch number: 2181 and the loss : 135952.046875\n",
      "Epoch number: 2191 and the loss : 134832.5\n",
      "Epoch number: 2201 and the loss : 134099.390625\n",
      "Epoch number: 2211 and the loss : 133808.578125\n",
      "Epoch number: 2221 and the loss : 132851.234375\n",
      "Epoch number: 2231 and the loss : 132640.390625\n",
      "Epoch number: 2241 and the loss : 131501.609375\n",
      "Epoch number: 2251 and the loss : 131649.25\n",
      "Epoch number: 2261 and the loss : 130293.6796875\n",
      "Epoch number: 2271 and the loss : 130355.984375\n",
      "Epoch number: 2281 and the loss : 130244.125\n",
      "Epoch number: 2291 and the loss : 129411.1875\n",
      "Epoch number: 2301 and the loss : 128880.828125\n",
      "Epoch number: 2311 and the loss : 129014.8671875\n",
      "Epoch number: 2321 and the loss : 128353.734375\n",
      "Epoch number: 2331 and the loss : 128660.1875\n",
      "Epoch number: 2341 and the loss : 127624.46875\n",
      "Epoch number: 2351 and the loss : 126356.75\n",
      "Epoch number: 2361 and the loss : 126277.3984375\n",
      "Epoch number: 2371 and the loss : 125785.3828125\n",
      "Epoch number: 2381 and the loss : 124836.71875\n",
      "Epoch number: 2391 and the loss : 124819.8828125\n",
      "Epoch number: 2401 and the loss : 124364.34375\n",
      "Epoch number: 2411 and the loss : 123199.4375\n",
      "Epoch number: 2421 and the loss : 123297.140625\n",
      "Epoch number: 2431 and the loss : 122402.53125\n",
      "Epoch number: 2441 and the loss : 122468.9375\n",
      "Epoch number: 2451 and the loss : 121331.5625\n",
      "Epoch number: 2461 and the loss : 120225.875\n",
      "Epoch number: 2471 and the loss : 120777.9375\n",
      "Epoch number: 2481 and the loss : 121238.140625\n",
      "Epoch number: 2491 and the loss : 120725.9609375\n",
      "Epoch number: 2501 and the loss : 119612.5234375\n",
      "Epoch number: 2511 and the loss : 118679.2109375\n",
      "Epoch number: 2521 and the loss : 117701.1875\n",
      "Epoch number: 2531 and the loss : 118361.59375\n",
      "Epoch number: 2541 and the loss : 117417.359375\n",
      "Epoch number: 2551 and the loss : 117113.0\n",
      "Epoch number: 2561 and the loss : 116284.796875\n",
      "Epoch number: 2571 and the loss : 115610.03125\n",
      "Epoch number: 2581 and the loss : 116079.953125\n",
      "Epoch number: 2591 and the loss : 115531.8046875\n",
      "Epoch number: 2601 and the loss : 114498.09375\n",
      "Epoch number: 2611 and the loss : 114406.90625\n",
      "Epoch number: 2621 and the loss : 114669.390625\n",
      "Epoch number: 2631 and the loss : 112625.3046875\n",
      "Epoch number: 2641 and the loss : 112181.7109375\n",
      "Epoch number: 2651 and the loss : 112259.546875\n",
      "Epoch number: 2661 and the loss : 111502.78125\n",
      "Epoch number: 2671 and the loss : 110846.8046875\n",
      "Epoch number: 2681 and the loss : 110125.359375\n",
      "Epoch number: 2691 and the loss : 109439.5859375\n",
      "Epoch number: 2701 and the loss : 109802.140625\n",
      "Epoch number: 2711 and the loss : 109236.5234375\n",
      "Epoch number: 2721 and the loss : 109001.90625\n",
      "Epoch number: 2731 and the loss : 108542.921875\n",
      "Epoch number: 2741 and the loss : 107164.09375\n",
      "Epoch number: 2751 and the loss : 105761.9296875\n",
      "Epoch number: 2761 and the loss : 106277.7265625\n",
      "Epoch number: 2771 and the loss : 106700.6484375\n",
      "Epoch number: 2781 and the loss : 106654.2890625\n",
      "Epoch number: 2791 and the loss : 104693.78125\n",
      "Epoch number: 2801 and the loss : 103624.921875\n",
      "Epoch number: 2811 and the loss : 103937.4765625\n",
      "Epoch number: 2821 and the loss : 102992.1484375\n",
      "Epoch number: 2831 and the loss : 103055.2265625\n",
      "Epoch number: 2841 and the loss : 102442.203125\n",
      "Epoch number: 2851 and the loss : 101385.3828125\n",
      "Epoch number: 2861 and the loss : 101760.9375\n",
      "Epoch number: 2871 and the loss : 100825.78125\n",
      "Epoch number: 2881 and the loss : 102197.78125\n",
      "Epoch number: 2891 and the loss : 100696.828125\n",
      "Epoch number: 2901 and the loss : 98936.203125\n",
      "Epoch number: 2911 and the loss : 98122.78125\n",
      "Epoch number: 2921 and the loss : 98331.5234375\n",
      "Epoch number: 2931 and the loss : 98854.96875\n",
      "Epoch number: 2941 and the loss : 96930.4765625\n",
      "Epoch number: 2951 and the loss : 97411.0625\n",
      "Epoch number: 2961 and the loss : 96635.015625\n",
      "Epoch number: 2971 and the loss : 95424.890625\n",
      "Epoch number: 2981 and the loss : 95115.84375\n",
      "Epoch number: 2991 and the loss : 94360.578125\n",
      "Epoch number: 3001 and the loss : 96061.6171875\n",
      "Epoch number: 3011 and the loss : 94195.7734375\n",
      "Epoch number: 3021 and the loss : 95945.3203125\n",
      "Epoch number: 3031 and the loss : 92743.8671875\n",
      "Epoch number: 3041 and the loss : 93283.7890625\n",
      "Epoch number: 3051 and the loss : 91540.5703125\n",
      "Epoch number: 3061 and the loss : 92311.578125\n",
      "Epoch number: 3071 and the loss : 91403.0859375\n",
      "Epoch number: 3081 and the loss : 90844.1953125\n",
      "Epoch number: 3091 and the loss : 89622.4375\n",
      "Epoch number: 3101 and the loss : 89247.9921875\n",
      "Epoch number: 3111 and the loss : 89145.2734375\n",
      "Epoch number: 3121 and the loss : 89457.8828125\n",
      "Epoch number: 3131 and the loss : 88000.1015625\n",
      "Epoch number: 3141 and the loss : 87973.9140625\n",
      "Epoch number: 3151 and the loss : 87724.546875\n",
      "Epoch number: 3161 and the loss : 86194.7578125\n",
      "Epoch number: 3171 and the loss : 86819.859375\n",
      "Epoch number: 3181 and the loss : 86338.0078125\n",
      "Epoch number: 3191 and the loss : 85027.0\n",
      "Epoch number: 3201 and the loss : 84867.09375\n",
      "Epoch number: 3211 and the loss : 84117.0234375\n",
      "Epoch number: 3221 and the loss : 82986.828125\n",
      "Epoch number: 3231 and the loss : 84034.09375\n",
      "Epoch number: 3241 and the loss : 82106.265625\n",
      "Epoch number: 3251 and the loss : 81537.15625\n",
      "Epoch number: 3261 and the loss : 84311.734375\n",
      "Epoch number: 3271 and the loss : 81995.1953125\n",
      "Epoch number: 3281 and the loss : 80851.3359375\n",
      "Epoch number: 3291 and the loss : 80717.890625\n",
      "Epoch number: 3301 and the loss : 79882.296875\n",
      "Epoch number: 3311 and the loss : 78774.0078125\n",
      "Epoch number: 3321 and the loss : 79468.046875\n",
      "Epoch number: 3331 and the loss : 78818.796875\n",
      "Epoch number: 3341 and the loss : 77772.2265625\n",
      "Epoch number: 3351 and the loss : 76728.5390625\n",
      "Epoch number: 3361 and the loss : 77016.3984375\n",
      "Epoch number: 3371 and the loss : 76401.6328125\n",
      "Epoch number: 3381 and the loss : 76380.6015625\n",
      "Epoch number: 3391 and the loss : 75024.9140625\n",
      "Epoch number: 3401 and the loss : 74318.4921875\n",
      "Epoch number: 3411 and the loss : 74536.3203125\n",
      "Epoch number: 3421 and the loss : 73943.3828125\n",
      "Epoch number: 3431 and the loss : 73726.0390625\n",
      "Epoch number: 3441 and the loss : 72729.0078125\n",
      "Epoch number: 3451 and the loss : 72794.8046875\n",
      "Epoch number: 3461 and the loss : 72459.9609375\n",
      "Epoch number: 3471 and the loss : 71025.59375\n",
      "Epoch number: 3481 and the loss : 70911.6484375\n",
      "Epoch number: 3491 and the loss : 70781.5625\n",
      "Epoch number: 3501 and the loss : 68950.7890625\n",
      "Epoch number: 3511 and the loss : 68973.6171875\n",
      "Epoch number: 3521 and the loss : 68951.7890625\n",
      "Epoch number: 3531 and the loss : 68308.9609375\n",
      "Epoch number: 3541 and the loss : 68221.453125\n",
      "Epoch number: 3551 and the loss : 67733.1875\n",
      "Epoch number: 3561 and the loss : 66090.9375\n",
      "Epoch number: 3571 and the loss : 65903.1796875\n",
      "Epoch number: 3581 and the loss : 65952.875\n",
      "Epoch number: 3591 and the loss : 66696.671875\n",
      "Epoch number: 3601 and the loss : 64659.2734375\n",
      "Epoch number: 3611 and the loss : 67893.625\n",
      "Epoch number: 3621 and the loss : 65163.41015625\n",
      "Epoch number: 3631 and the loss : 62969.8359375\n",
      "Epoch number: 3641 and the loss : 64641.79296875\n",
      "Epoch number: 3651 and the loss : 62560.4921875\n",
      "Epoch number: 3661 and the loss : 63921.859375\n",
      "Epoch number: 3671 and the loss : 61907.6796875\n",
      "Epoch number: 3681 and the loss : 61024.01171875\n",
      "Epoch number: 3691 and the loss : 61309.203125\n",
      "Epoch number: 3701 and the loss : 59706.58984375\n",
      "Epoch number: 3711 and the loss : 61777.625\n",
      "Epoch number: 3721 and the loss : 59721.3203125\n",
      "Epoch number: 3731 and the loss : 57389.953125\n",
      "Epoch number: 3741 and the loss : 57716.77734375\n",
      "Epoch number: 3751 and the loss : 59323.55859375\n",
      "Epoch number: 3761 and the loss : 58451.609375\n",
      "Epoch number: 3771 and the loss : 57266.1640625\n",
      "Epoch number: 3781 and the loss : 56462.23046875\n",
      "Epoch number: 3791 and the loss : 56728.05078125\n",
      "Epoch number: 3801 and the loss : 55834.92578125\n",
      "Epoch number: 3811 and the loss : 56324.62890625\n",
      "Epoch number: 3821 and the loss : 56457.96875\n",
      "Epoch number: 3831 and the loss : 54079.6015625\n",
      "Epoch number: 3841 and the loss : 56851.3984375\n",
      "Epoch number: 3851 and the loss : 54990.4375\n",
      "Epoch number: 3861 and the loss : 54401.41796875\n",
      "Epoch number: 3871 and the loss : 52129.59765625\n",
      "Epoch number: 3881 and the loss : 51988.42578125\n",
      "Epoch number: 3891 and the loss : 50473.91796875\n",
      "Epoch number: 3901 and the loss : 53340.8671875\n",
      "Epoch number: 3911 and the loss : 52275.8359375\n",
      "Epoch number: 3921 and the loss : 51026.97265625\n",
      "Epoch number: 3931 and the loss : 50905.078125\n",
      "Epoch number: 3941 and the loss : 50332.5234375\n",
      "Epoch number: 3951 and the loss : 48807.171875\n",
      "Epoch number: 3961 and the loss : 51696.734375\n",
      "Epoch number: 3971 and the loss : 49376.9609375\n",
      "Epoch number: 3981 and the loss : 49198.23046875\n",
      "Epoch number: 3991 and the loss : 49857.65625\n",
      "Epoch number: 4001 and the loss : 48447.03125\n",
      "Epoch number: 4011 and the loss : 46904.37109375\n",
      "Epoch number: 4021 and the loss : 49187.03125\n",
      "Epoch number: 4031 and the loss : 45892.4609375\n",
      "Epoch number: 4041 and the loss : 47917.33203125\n",
      "Epoch number: 4051 and the loss : 47761.73046875\n",
      "Epoch number: 4061 and the loss : 44905.68359375\n",
      "Epoch number: 4071 and the loss : 45409.88671875\n",
      "Epoch number: 4081 and the loss : 44242.86328125\n",
      "Epoch number: 4091 and the loss : 45681.30859375\n",
      "Epoch number: 4101 and the loss : 44189.546875\n",
      "Epoch number: 4111 and the loss : 44150.38671875\n",
      "Epoch number: 4121 and the loss : 45010.78515625\n",
      "Epoch number: 4131 and the loss : 43341.0078125\n",
      "Epoch number: 4141 and the loss : 44571.4921875\n",
      "Epoch number: 4151 and the loss : 43140.66796875\n",
      "Epoch number: 4161 and the loss : 42339.125\n",
      "Epoch number: 4171 and the loss : 42103.4140625\n",
      "Epoch number: 4181 and the loss : 42494.453125\n",
      "Epoch number: 4191 and the loss : 47166.2890625\n",
      "Epoch number: 4201 and the loss : 42137.02734375\n",
      "Epoch number: 4211 and the loss : 41017.078125\n",
      "Epoch number: 4221 and the loss : 39974.890625\n",
      "Epoch number: 4231 and the loss : 40664.84375\n",
      "Epoch number: 4241 and the loss : 40078.5390625\n",
      "Epoch number: 4251 and the loss : 39782.39453125\n",
      "Epoch number: 4261 and the loss : 41148.03125\n",
      "Epoch number: 4271 and the loss : 40820.125\n",
      "Epoch number: 4281 and the loss : 41923.40625\n",
      "Epoch number: 4291 and the loss : 39118.28125\n",
      "Epoch number: 4301 and the loss : 40426.31640625\n",
      "Epoch number: 4311 and the loss : 39596.33984375\n",
      "Epoch number: 4321 and the loss : 39976.4140625\n",
      "Epoch number: 4331 and the loss : 39414.62890625\n",
      "Epoch number: 4341 and the loss : 39400.46875\n",
      "Epoch number: 4351 and the loss : 42139.4375\n",
      "Epoch number: 4361 and the loss : 39131.16796875\n",
      "Epoch number: 4371 and the loss : 38201.37109375\n",
      "Epoch number: 4381 and the loss : 38103.6015625\n",
      "Epoch number: 4391 and the loss : 36899.87890625\n",
      "Epoch number: 4401 and the loss : 37454.07421875\n",
      "Epoch number: 4411 and the loss : 38820.3359375\n",
      "Epoch number: 4421 and the loss : 39024.921875\n",
      "Epoch number: 4431 and the loss : 38737.0859375\n",
      "Epoch number: 4441 and the loss : 37969.40234375\n",
      "Epoch number: 4451 and the loss : 37805.98828125\n",
      "Epoch number: 4461 and the loss : 37804.3125\n",
      "Epoch number: 4471 and the loss : 37769.4921875\n",
      "Epoch number: 4481 and the loss : 37253.6484375\n",
      "Epoch number: 4491 and the loss : 36808.83203125\n",
      "Epoch number: 4501 and the loss : 39103.5078125\n",
      "Epoch number: 4511 and the loss : 37020.546875\n",
      "Epoch number: 4521 and the loss : 36955.40625\n",
      "Epoch number: 4531 and the loss : 37245.796875\n",
      "Epoch number: 4541 and the loss : 35753.30078125\n",
      "Epoch number: 4551 and the loss : 35716.5078125\n",
      "Epoch number: 4561 and the loss : 36457.8203125\n",
      "Epoch number: 4571 and the loss : 37555.56640625\n",
      "Epoch number: 4581 and the loss : 36291.3046875\n",
      "Epoch number: 4591 and the loss : 35025.09765625\n",
      "Epoch number: 4601 and the loss : 36946.58984375\n",
      "Epoch number: 4611 and the loss : 35747.42578125\n",
      "Epoch number: 4621 and the loss : 35659.41796875\n",
      "Epoch number: 4631 and the loss : 36142.890625\n",
      "Epoch number: 4641 and the loss : 35148.88671875\n",
      "Epoch number: 4651 and the loss : 35743.66796875\n",
      "Epoch number: 4661 and the loss : 35174.55078125\n",
      "Epoch number: 4671 and the loss : 37417.4765625\n",
      "Epoch number: 4681 and the loss : 36820.35546875\n",
      "Epoch number: 4691 and the loss : 38307.00390625\n",
      "Epoch number: 4701 and the loss : 35112.609375\n",
      "Epoch number: 4711 and the loss : 34047.04296875\n",
      "Epoch number: 4721 and the loss : 36026.1875\n",
      "Epoch number: 4731 and the loss : 34968.15625\n",
      "Epoch number: 4741 and the loss : 34776.98828125\n",
      "Epoch number: 4751 and the loss : 35786.58203125\n",
      "Epoch number: 4761 and the loss : 35531.93359375\n",
      "Epoch number: 4771 and the loss : 36198.92578125\n",
      "Epoch number: 4781 and the loss : 34107.07421875\n",
      "Epoch number: 4791 and the loss : 35853.37109375\n",
      "Epoch number: 4801 and the loss : 38418.37890625\n",
      "Epoch number: 4811 and the loss : 36189.00390625\n",
      "Epoch number: 4821 and the loss : 34885.40625\n",
      "Epoch number: 4831 and the loss : 35538.11328125\n",
      "Epoch number: 4841 and the loss : 35380.31640625\n",
      "Epoch number: 4851 and the loss : 36673.53125\n",
      "Epoch number: 4861 and the loss : 35579.125\n",
      "Epoch number: 4871 and the loss : 35090.73046875\n",
      "Epoch number: 4881 and the loss : 36989.98828125\n",
      "Epoch number: 4891 and the loss : 35701.7890625\n",
      "Epoch number: 4901 and the loss : 36537.5390625\n",
      "Epoch number: 4911 and the loss : 35832.01171875\n",
      "Epoch number: 4921 and the loss : 35309.64453125\n",
      "Epoch number: 4931 and the loss : 36275.46875\n",
      "Epoch number: 4941 and the loss : 36603.2265625\n",
      "Epoch number: 4951 and the loss : 34021.0390625\n",
      "Epoch number: 4961 and the loss : 35458.2265625\n",
      "Epoch number: 4971 and the loss : 36955.2578125\n",
      "Epoch number: 4981 and the loss : 35565.31640625\n",
      "Epoch number: 4991 and the loss : 33851.953125\n"
     ]
    }
   ],
   "source": [
    "epochs=5000\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i = i + 1\n",
    "    y_pred = model(train_categorical,train_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\n",
    "    final_losses.append(loss)\n",
    "    if i % 10 == 1:\n",
    "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
    "    optimizer.zero_grad() # resets the optimizer\n",
    "    loss.backward() # does the back propogation with .backward() function\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3650034c-4d63-4713-8946-f8e5f2298298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(200496.75, dtype=float32),\n",
       " array(200496.4, dtype=float32),\n",
       " array(200496.06, dtype=float32),\n",
       " array(200495.73, dtype=float32),\n",
       " array(200495.4, dtype=float32),\n",
       " array(200495.14, dtype=float32),\n",
       " array(200494.78, dtype=float32),\n",
       " array(200494.5, dtype=float32),\n",
       " array(200494.17, dtype=float32),\n",
       " array(200493.81, dtype=float32),\n",
       " array(200493.47, dtype=float32),\n",
       " array(200493.17, dtype=float32),\n",
       " array(200492.75, dtype=float32),\n",
       " array(200492.28, dtype=float32),\n",
       " array(200492.03, dtype=float32),\n",
       " array(200491.52, dtype=float32),\n",
       " array(200491.06, dtype=float32),\n",
       " array(200490.6, dtype=float32),\n",
       " array(200490.06, dtype=float32),\n",
       " array(200489.6, dtype=float32),\n",
       " array(200489.14, dtype=float32),\n",
       " array(200488.31, dtype=float32),\n",
       " array(200488., dtype=float32),\n",
       " array(200487.4, dtype=float32),\n",
       " array(200486.8, dtype=float32),\n",
       " array(200485.9, dtype=float32),\n",
       " array(200485.53, dtype=float32),\n",
       " array(200484.64, dtype=float32),\n",
       " array(200484.08, dtype=float32),\n",
       " array(200483.25, dtype=float32),\n",
       " array(200482.64, dtype=float32),\n",
       " array(200481.53, dtype=float32),\n",
       " array(200481.03, dtype=float32),\n",
       " array(200479.95, dtype=float32),\n",
       " array(200479.05, dtype=float32),\n",
       " array(200478.31, dtype=float32),\n",
       " array(200476.9, dtype=float32),\n",
       " array(200476.34, dtype=float32),\n",
       " array(200475.19, dtype=float32),\n",
       " array(200474.31, dtype=float32),\n",
       " array(200473.25, dtype=float32),\n",
       " array(200472.44, dtype=float32),\n",
       " array(200471.42, dtype=float32),\n",
       " array(200470.45, dtype=float32),\n",
       " array(200469.12, dtype=float32),\n",
       " array(200468.08, dtype=float32),\n",
       " array(200466.39, dtype=float32),\n",
       " array(200465.19, dtype=float32),\n",
       " array(200464.16, dtype=float32),\n",
       " array(200462.69, dtype=float32),\n",
       " array(200461.38, dtype=float32),\n",
       " array(200460.33, dtype=float32),\n",
       " array(200458.64, dtype=float32),\n",
       " array(200456.73, dtype=float32),\n",
       " array(200455.4, dtype=float32),\n",
       " array(200454.4, dtype=float32),\n",
       " array(200453.3, dtype=float32),\n",
       " array(200451.08, dtype=float32),\n",
       " array(200450.05, dtype=float32),\n",
       " array(200448.3, dtype=float32),\n",
       " array(200446.4, dtype=float32),\n",
       " array(200445.25, dtype=float32),\n",
       " array(200443.56, dtype=float32),\n",
       " array(200441.67, dtype=float32),\n",
       " array(200439.27, dtype=float32),\n",
       " array(200438.16, dtype=float32),\n",
       " array(200436.4, dtype=float32),\n",
       " array(200433.58, dtype=float32),\n",
       " array(200432.55, dtype=float32),\n",
       " array(200430.19, dtype=float32),\n",
       " array(200429.36, dtype=float32),\n",
       " array(200426.2, dtype=float32),\n",
       " array(200424.64, dtype=float32),\n",
       " array(200424.05, dtype=float32),\n",
       " array(200421.52, dtype=float32),\n",
       " array(200417.9, dtype=float32),\n",
       " array(200416.14, dtype=float32),\n",
       " array(200415.3, dtype=float32),\n",
       " array(200411.81, dtype=float32),\n",
       " array(200410.39, dtype=float32),\n",
       " array(200408., dtype=float32),\n",
       " array(200404.86, dtype=float32),\n",
       " array(200402.72, dtype=float32),\n",
       " array(200400.36, dtype=float32),\n",
       " array(200399.02, dtype=float32),\n",
       " array(200397.44, dtype=float32),\n",
       " array(200393., dtype=float32),\n",
       " array(200391.81, dtype=float32),\n",
       " array(200387.2, dtype=float32),\n",
       " array(200386.61, dtype=float32),\n",
       " array(200383.42, dtype=float32),\n",
       " array(200380.83, dtype=float32),\n",
       " array(200378.23, dtype=float32),\n",
       " array(200374.53, dtype=float32),\n",
       " array(200372.44, dtype=float32),\n",
       " array(200371.45, dtype=float32),\n",
       " array(200367.17, dtype=float32),\n",
       " array(200364.16, dtype=float32),\n",
       " array(200360.17, dtype=float32),\n",
       " array(200359.11, dtype=float32),\n",
       " array(200355.31, dtype=float32),\n",
       " array(200350.73, dtype=float32),\n",
       " array(200350.2, dtype=float32),\n",
       " array(200344.88, dtype=float32),\n",
       " array(200342.84, dtype=float32),\n",
       " array(200339.6, dtype=float32),\n",
       " array(200337.02, dtype=float32),\n",
       " array(200333.2, dtype=float32),\n",
       " array(200331.19, dtype=float32),\n",
       " array(200323.62, dtype=float32),\n",
       " array(200322.12, dtype=float32),\n",
       " array(200320.3, dtype=float32),\n",
       " array(200315.84, dtype=float32),\n",
       " array(200316.5, dtype=float32),\n",
       " array(200307.62, dtype=float32),\n",
       " array(200304.56, dtype=float32),\n",
       " array(200303.14, dtype=float32),\n",
       " array(200297.69, dtype=float32),\n",
       " array(200294.9, dtype=float32),\n",
       " array(200294.19, dtype=float32),\n",
       " array(200291.44, dtype=float32),\n",
       " array(200286., dtype=float32),\n",
       " array(200282.56, dtype=float32),\n",
       " array(200276.75, dtype=float32),\n",
       " array(200272.94, dtype=float32),\n",
       " array(200269.58, dtype=float32),\n",
       " array(200265.14, dtype=float32),\n",
       " array(200261.19, dtype=float32),\n",
       " array(200260.31, dtype=float32),\n",
       " array(200256.58, dtype=float32),\n",
       " array(200252.02, dtype=float32),\n",
       " array(200246.6, dtype=float32),\n",
       " array(200242.1, dtype=float32),\n",
       " array(200239.55, dtype=float32),\n",
       " array(200233.97, dtype=float32),\n",
       " array(200227.53, dtype=float32),\n",
       " array(200225.77, dtype=float32),\n",
       " array(200219.61, dtype=float32),\n",
       " array(200220.27, dtype=float32),\n",
       " array(200215.75, dtype=float32),\n",
       " array(200206.6, dtype=float32),\n",
       " array(200203.2, dtype=float32),\n",
       " array(200202.17, dtype=float32),\n",
       " array(200197.77, dtype=float32),\n",
       " array(200192.3, dtype=float32),\n",
       " array(200184.88, dtype=float32),\n",
       " array(200181.31, dtype=float32),\n",
       " array(200174.44, dtype=float32),\n",
       " array(200175.1, dtype=float32),\n",
       " array(200170.98, dtype=float32),\n",
       " array(200162.23, dtype=float32),\n",
       " array(200152.72, dtype=float32),\n",
       " array(200148.64, dtype=float32),\n",
       " array(200149.83, dtype=float32),\n",
       " array(200141.83, dtype=float32),\n",
       " array(200133.53, dtype=float32),\n",
       " array(200136.28, dtype=float32),\n",
       " array(200129.77, dtype=float32),\n",
       " array(200120.1, dtype=float32),\n",
       " array(200115.44, dtype=float32),\n",
       " array(200112.23, dtype=float32),\n",
       " array(200109.66, dtype=float32),\n",
       " array(200100.34, dtype=float32),\n",
       " array(200099.48, dtype=float32),\n",
       " array(200087.17, dtype=float32),\n",
       " array(200089.94, dtype=float32),\n",
       " array(200079.92, dtype=float32),\n",
       " array(200082.39, dtype=float32),\n",
       " array(200071.95, dtype=float32),\n",
       " array(200071.61, dtype=float32),\n",
       " array(200059.62, dtype=float32),\n",
       " array(200061.1, dtype=float32),\n",
       " array(200043.81, dtype=float32),\n",
       " array(200049.81, dtype=float32),\n",
       " array(200038.33, dtype=float32),\n",
       " array(200032.67, dtype=float32),\n",
       " array(200026.17, dtype=float32),\n",
       " array(200012.45, dtype=float32),\n",
       " array(200016.53, dtype=float32),\n",
       " array(200011.81, dtype=float32),\n",
       " array(200005.75, dtype=float32),\n",
       " array(199996.67, dtype=float32),\n",
       " array(199993.66, dtype=float32),\n",
       " array(199988.22, dtype=float32),\n",
       " array(199983.73, dtype=float32),\n",
       " array(199969.83, dtype=float32),\n",
       " array(199968.75, dtype=float32),\n",
       " array(199962.33, dtype=float32),\n",
       " array(199957.3, dtype=float32),\n",
       " array(199951.84, dtype=float32),\n",
       " array(199946.4, dtype=float32),\n",
       " array(199933.52, dtype=float32),\n",
       " array(199934.81, dtype=float32),\n",
       " array(199921.03, dtype=float32),\n",
       " array(199917.72, dtype=float32),\n",
       " array(199912.61, dtype=float32),\n",
       " array(199911.78, dtype=float32),\n",
       " array(199898.4, dtype=float32),\n",
       " array(199889.3, dtype=float32),\n",
       " array(199879.44, dtype=float32),\n",
       " array(199881.55, dtype=float32),\n",
       " array(199865.97, dtype=float32),\n",
       " array(199863.62, dtype=float32),\n",
       " array(199854.48, dtype=float32),\n",
       " array(199855.08, dtype=float32),\n",
       " array(199843.25, dtype=float32),\n",
       " array(199839.7, dtype=float32),\n",
       " array(199838.48, dtype=float32),\n",
       " array(199824.61, dtype=float32),\n",
       " array(199820.23, dtype=float32),\n",
       " array(199815.78, dtype=float32),\n",
       " array(199806.11, dtype=float32),\n",
       " array(199799.11, dtype=float32),\n",
       " array(199794.28, dtype=float32),\n",
       " array(199783.12, dtype=float32),\n",
       " array(199778.12, dtype=float32),\n",
       " array(199766.47, dtype=float32),\n",
       " array(199772.14, dtype=float32),\n",
       " array(199755.84, dtype=float32),\n",
       " array(199750.03, dtype=float32),\n",
       " array(199736.97, dtype=float32),\n",
       " array(199729.94, dtype=float32),\n",
       " array(199731.72, dtype=float32),\n",
       " array(199721.75, dtype=float32),\n",
       " array(199707.7, dtype=float32),\n",
       " array(199698.97, dtype=float32),\n",
       " array(199689.83, dtype=float32),\n",
       " array(199681.2, dtype=float32),\n",
       " array(199675.42, dtype=float32),\n",
       " array(199682.31, dtype=float32),\n",
       " array(199668.89, dtype=float32),\n",
       " array(199661.1, dtype=float32),\n",
       " array(199649.45, dtype=float32),\n",
       " array(199639.78, dtype=float32),\n",
       " array(199620.6, dtype=float32),\n",
       " array(199622.27, dtype=float32),\n",
       " array(199614.64, dtype=float32),\n",
       " array(199611.3, dtype=float32),\n",
       " array(199604.45, dtype=float32),\n",
       " array(199593.22, dtype=float32),\n",
       " array(199589.02, dtype=float32),\n",
       " array(199581.25, dtype=float32),\n",
       " array(199585.03, dtype=float32),\n",
       " array(199569.36, dtype=float32),\n",
       " array(199560.64, dtype=float32),\n",
       " array(199541.31, dtype=float32),\n",
       " array(199531.5, dtype=float32),\n",
       " array(199534.98, dtype=float32),\n",
       " array(199517.77, dtype=float32),\n",
       " array(199507.9, dtype=float32),\n",
       " array(199505.34, dtype=float32),\n",
       " array(199496.9, dtype=float32),\n",
       " array(199481.25, dtype=float32),\n",
       " array(199491.12, dtype=float32),\n",
       " array(199469.45, dtype=float32),\n",
       " array(199459.11, dtype=float32),\n",
       " array(199442.73, dtype=float32),\n",
       " array(199451.03, dtype=float32),\n",
       " array(199437.92, dtype=float32),\n",
       " array(199418.38, dtype=float32),\n",
       " array(199410.92, dtype=float32),\n",
       " array(199409.2, dtype=float32),\n",
       " array(199410.83, dtype=float32),\n",
       " array(199386.97, dtype=float32),\n",
       " array(199395.61, dtype=float32),\n",
       " array(199397.56, dtype=float32),\n",
       " array(199375.86, dtype=float32),\n",
       " array(199351.55, dtype=float32),\n",
       " array(199355.6, dtype=float32),\n",
       " array(199351.06, dtype=float32),\n",
       " array(199324.38, dtype=float32),\n",
       " array(199315.16, dtype=float32),\n",
       " array(199306.2, dtype=float32),\n",
       " array(199311.67, dtype=float32),\n",
       " array(199291.05, dtype=float32),\n",
       " array(199278.52, dtype=float32),\n",
       " array(199282.39, dtype=float32),\n",
       " array(199284.31, dtype=float32),\n",
       " array(199271.28, dtype=float32),\n",
       " array(199231.64, dtype=float32),\n",
       " array(199243.11, dtype=float32),\n",
       " array(199217.8, dtype=float32),\n",
       " array(199235.19, dtype=float32),\n",
       " array(199225.61, dtype=float32),\n",
       " array(199213.3, dtype=float32),\n",
       " array(199183.53, dtype=float32),\n",
       " array(199179.95, dtype=float32),\n",
       " array(199171.69, dtype=float32),\n",
       " array(199150.16, dtype=float32),\n",
       " array(199146.47, dtype=float32),\n",
       " array(199141.3, dtype=float32),\n",
       " array(199114.78, dtype=float32),\n",
       " array(199121.69, dtype=float32),\n",
       " array(199105.73, dtype=float32),\n",
       " array(199097.75, dtype=float32),\n",
       " array(199117.28, dtype=float32),\n",
       " array(199087.22, dtype=float32),\n",
       " array(199052.27, dtype=float32),\n",
       " array(199045.11, dtype=float32),\n",
       " array(199061.16, dtype=float32),\n",
       " array(199027.05, dtype=float32),\n",
       " array(199025.94, dtype=float32),\n",
       " array(199029.92, dtype=float32),\n",
       " array(199026.75, dtype=float32),\n",
       " array(198985.72, dtype=float32),\n",
       " array(199000.19, dtype=float32),\n",
       " array(198971.61, dtype=float32),\n",
       " array(198966.58, dtype=float32),\n",
       " array(198975.64, dtype=float32),\n",
       " array(198939.36, dtype=float32),\n",
       " array(198931.73, dtype=float32),\n",
       " array(198922.06, dtype=float32),\n",
       " array(198913.4, dtype=float32),\n",
       " array(198898.64, dtype=float32),\n",
       " array(198892.94, dtype=float32),\n",
       " array(198895.25, dtype=float32),\n",
       " array(198871.73, dtype=float32),\n",
       " array(198850.95, dtype=float32),\n",
       " array(198859.89, dtype=float32),\n",
       " array(198836.44, dtype=float32),\n",
       " array(198845.16, dtype=float32),\n",
       " array(198818.02, dtype=float32),\n",
       " array(198845.52, dtype=float32),\n",
       " array(198798.94, dtype=float32),\n",
       " array(198793.94, dtype=float32),\n",
       " array(198760.2, dtype=float32),\n",
       " array(198769.05, dtype=float32),\n",
       " array(198753.52, dtype=float32),\n",
       " array(198748.44, dtype=float32),\n",
       " array(198748.81, dtype=float32),\n",
       " array(198694.66, dtype=float32),\n",
       " array(198682.48, dtype=float32),\n",
       " array(198676.81, dtype=float32),\n",
       " array(198685.02, dtype=float32),\n",
       " array(198704.58, dtype=float32),\n",
       " array(198663.4, dtype=float32),\n",
       " array(198660.98, dtype=float32),\n",
       " array(198637.33, dtype=float32),\n",
       " array(198639.19, dtype=float32),\n",
       " array(198623.86, dtype=float32),\n",
       " array(198602.84, dtype=float32),\n",
       " array(198606.1, dtype=float32),\n",
       " array(198576.45, dtype=float32),\n",
       " array(198569.3, dtype=float32),\n",
       " array(198524.33, dtype=float32),\n",
       " array(198558.81, dtype=float32),\n",
       " array(198556.48, dtype=float32),\n",
       " array(198540.03, dtype=float32),\n",
       " array(198543.67, dtype=float32),\n",
       " array(198521.98, dtype=float32),\n",
       " array(198491.44, dtype=float32),\n",
       " array(198491.23, dtype=float32),\n",
       " array(198448.84, dtype=float32),\n",
       " array(198468.92, dtype=float32),\n",
       " array(198434.17, dtype=float32),\n",
       " array(198406., dtype=float32),\n",
       " array(198437.64, dtype=float32),\n",
       " array(198398.44, dtype=float32),\n",
       " array(198403.3, dtype=float32),\n",
       " array(198385.55, dtype=float32),\n",
       " array(198385.02, dtype=float32),\n",
       " array(198364.98, dtype=float32),\n",
       " array(198375.2, dtype=float32),\n",
       " array(198347.06, dtype=float32),\n",
       " array(198310.06, dtype=float32),\n",
       " array(198327.34, dtype=float32),\n",
       " array(198299.89, dtype=float32),\n",
       " array(198305.31, dtype=float32),\n",
       " array(198299.9, dtype=float32),\n",
       " array(198248.47, dtype=float32),\n",
       " array(198244.52, dtype=float32),\n",
       " array(198236.4, dtype=float32),\n",
       " array(198202.08, dtype=float32),\n",
       " array(198199.81, dtype=float32),\n",
       " array(198187.16, dtype=float32),\n",
       " array(198169.36, dtype=float32),\n",
       " array(198151.4, dtype=float32),\n",
       " array(198151.31, dtype=float32),\n",
       " array(198139.86, dtype=float32),\n",
       " array(198109.58, dtype=float32),\n",
       " array(198104.19, dtype=float32),\n",
       " array(198136.69, dtype=float32),\n",
       " array(198138.28, dtype=float32),\n",
       " array(198090.7, dtype=float32),\n",
       " array(198082.69, dtype=float32),\n",
       " array(198083.72, dtype=float32),\n",
       " array(198025.97, dtype=float32),\n",
       " array(198028.55, dtype=float32),\n",
       " array(198044.88, dtype=float32),\n",
       " array(198004.52, dtype=float32),\n",
       " array(198014.3, dtype=float32),\n",
       " array(197997.38, dtype=float32),\n",
       " array(197970.69, dtype=float32),\n",
       " array(197936.55, dtype=float32),\n",
       " array(197968.14, dtype=float32),\n",
       " array(197891.39, dtype=float32),\n",
       " array(197951.47, dtype=float32),\n",
       " array(197896.1, dtype=float32),\n",
       " array(197871.03, dtype=float32),\n",
       " array(197873.47, dtype=float32),\n",
       " array(197883.81, dtype=float32),\n",
       " array(197827.75, dtype=float32),\n",
       " array(197830.12, dtype=float32),\n",
       " array(197804.47, dtype=float32),\n",
       " array(197843.31, dtype=float32),\n",
       " array(197762.25, dtype=float32),\n",
       " array(197786.89, dtype=float32),\n",
       " array(197754.69, dtype=float32),\n",
       " array(197760.61, dtype=float32),\n",
       " array(197751.69, dtype=float32),\n",
       " array(197728.31, dtype=float32),\n",
       " array(197717.42, dtype=float32),\n",
       " array(197660.06, dtype=float32),\n",
       " array(197710.67, dtype=float32),\n",
       " array(197673.19, dtype=float32),\n",
       " array(197653.67, dtype=float32),\n",
       " array(197626.33, dtype=float32),\n",
       " array(197613.89, dtype=float32),\n",
       " array(197628.45, dtype=float32),\n",
       " array(197596.27, dtype=float32),\n",
       " array(197595.25, dtype=float32),\n",
       " array(197518.66, dtype=float32),\n",
       " array(197599.23, dtype=float32),\n",
       " array(197518.48, dtype=float32),\n",
       " array(197577.06, dtype=float32),\n",
       " array(197507.47, dtype=float32),\n",
       " array(197488.42, dtype=float32),\n",
       " array(197489.22, dtype=float32),\n",
       " array(197454.22, dtype=float32),\n",
       " array(197453.9, dtype=float32),\n",
       " array(197424.34, dtype=float32),\n",
       " array(197403., dtype=float32),\n",
       " array(197418.89, dtype=float32),\n",
       " array(197445.17, dtype=float32),\n",
       " array(197421.73, dtype=float32),\n",
       " array(197329.83, dtype=float32),\n",
       " array(197321.75, dtype=float32),\n",
       " array(197333.97, dtype=float32),\n",
       " array(197354.64, dtype=float32),\n",
       " array(197259.03, dtype=float32),\n",
       " array(197283.25, dtype=float32),\n",
       " array(197268.28, dtype=float32),\n",
       " array(197272.02, dtype=float32),\n",
       " array(197260.83, dtype=float32),\n",
       " array(197223.88, dtype=float32),\n",
       " array(197172.33, dtype=float32),\n",
       " array(197216.56, dtype=float32),\n",
       " array(197192.88, dtype=float32),\n",
       " array(197210.08, dtype=float32),\n",
       " array(197143.1, dtype=float32),\n",
       " array(197170.42, dtype=float32),\n",
       " array(197134.92, dtype=float32),\n",
       " array(197151.48, dtype=float32),\n",
       " array(197107.67, dtype=float32),\n",
       " array(197104.25, dtype=float32),\n",
       " array(197052.72, dtype=float32),\n",
       " array(197000.06, dtype=float32),\n",
       " array(197050.33, dtype=float32),\n",
       " array(197063.48, dtype=float32),\n",
       " array(197003.61, dtype=float32),\n",
       " array(196963.33, dtype=float32),\n",
       " array(196998.05, dtype=float32),\n",
       " array(196970.42, dtype=float32),\n",
       " array(196947.22, dtype=float32),\n",
       " array(196901.55, dtype=float32),\n",
       " array(196875.02, dtype=float32),\n",
       " array(196860.03, dtype=float32),\n",
       " array(196894.11, dtype=float32),\n",
       " array(196832.28, dtype=float32),\n",
       " array(196917.86, dtype=float32),\n",
       " array(196877.88, dtype=float32),\n",
       " array(196867.61, dtype=float32),\n",
       " array(196804.67, dtype=float32),\n",
       " array(196807.92, dtype=float32),\n",
       " array(196768.48, dtype=float32),\n",
       " array(196800.16, dtype=float32),\n",
       " array(196744.69, dtype=float32),\n",
       " array(196729.14, dtype=float32),\n",
       " array(196755.58, dtype=float32),\n",
       " array(196666.14, dtype=float32),\n",
       " array(196702.67, dtype=float32),\n",
       " array(196652.4, dtype=float32),\n",
       " array(196630.83, dtype=float32),\n",
       " array(196674.86, dtype=float32),\n",
       " array(196580.06, dtype=float32),\n",
       " array(196611.98, dtype=float32),\n",
       " array(196546.17, dtype=float32),\n",
       " array(196556.64, dtype=float32),\n",
       " array(196530.56, dtype=float32),\n",
       " array(196572.58, dtype=float32),\n",
       " array(196502.95, dtype=float32),\n",
       " array(196548.55, dtype=float32),\n",
       " array(196466.88, dtype=float32),\n",
       " array(196439.33, dtype=float32),\n",
       " array(196466.47, dtype=float32),\n",
       " array(196525.34, dtype=float32),\n",
       " array(196450.61, dtype=float32),\n",
       " array(196415.3, dtype=float32),\n",
       " array(196378.75, dtype=float32),\n",
       " array(196371.92, dtype=float32),\n",
       " array(196434., dtype=float32),\n",
       " array(196337.52, dtype=float32),\n",
       " array(196273., dtype=float32),\n",
       " array(196319.72, dtype=float32),\n",
       " array(196317.4, dtype=float32),\n",
       " array(196236.84, dtype=float32),\n",
       " array(196230.78, dtype=float32),\n",
       " array(196208.9, dtype=float32),\n",
       " array(196188.73, dtype=float32),\n",
       " array(196129.98, dtype=float32),\n",
       " array(196209.92, dtype=float32),\n",
       " array(196159.19, dtype=float32),\n",
       " array(196120.2, dtype=float32),\n",
       " array(196141.58, dtype=float32),\n",
       " array(196100.86, dtype=float32),\n",
       " array(196085.62, dtype=float32),\n",
       " array(196054.97, dtype=float32),\n",
       " array(196052.6, dtype=float32),\n",
       " array(196056.19, dtype=float32),\n",
       " array(196010.78, dtype=float32),\n",
       " array(196042.44, dtype=float32),\n",
       " array(196008.34, dtype=float32),\n",
       " array(195969.9, dtype=float32),\n",
       " array(195966.08, dtype=float32),\n",
       " array(195970.67, dtype=float32),\n",
       " array(195911.73, dtype=float32),\n",
       " array(195907.8, dtype=float32),\n",
       " array(195878.53, dtype=float32),\n",
       " array(195848.64, dtype=float32),\n",
       " array(195945.92, dtype=float32),\n",
       " array(195848.36, dtype=float32),\n",
       " array(195875.02, dtype=float32),\n",
       " array(195787.34, dtype=float32),\n",
       " array(195754.97, dtype=float32),\n",
       " array(195698.72, dtype=float32),\n",
       " array(195775.42, dtype=float32),\n",
       " array(195774.84, dtype=float32),\n",
       " array(195745.4, dtype=float32),\n",
       " array(195676.81, dtype=float32),\n",
       " array(195680.19, dtype=float32),\n",
       " array(195662.31, dtype=float32),\n",
       " array(195649.73, dtype=float32),\n",
       " array(195586.5, dtype=float32),\n",
       " array(195531.67, dtype=float32),\n",
       " array(195633.78, dtype=float32),\n",
       " array(195522.14, dtype=float32),\n",
       " array(195571.77, dtype=float32),\n",
       " array(195570.69, dtype=float32),\n",
       " array(195499.17, dtype=float32),\n",
       " array(195540.17, dtype=float32),\n",
       " array(195458.78, dtype=float32),\n",
       " array(195440.69, dtype=float32),\n",
       " array(195451.6, dtype=float32),\n",
       " array(195412.55, dtype=float32),\n",
       " array(195343.12, dtype=float32),\n",
       " array(195464.03, dtype=float32),\n",
       " array(195360.55, dtype=float32),\n",
       " array(195316.92, dtype=float32),\n",
       " array(195238.11, dtype=float32),\n",
       " array(195333.6, dtype=float32),\n",
       " array(195286.52, dtype=float32),\n",
       " array(195231.42, dtype=float32),\n",
       " array(195277.97, dtype=float32),\n",
       " array(195228.28, dtype=float32),\n",
       " array(195200.81, dtype=float32),\n",
       " array(195162.67, dtype=float32),\n",
       " array(195106.28, dtype=float32),\n",
       " array(195165.58, dtype=float32),\n",
       " array(195183.89, dtype=float32),\n",
       " array(195066.42, dtype=float32),\n",
       " array(195070.48, dtype=float32),\n",
       " array(195084.53, dtype=float32),\n",
       " array(195037.52, dtype=float32),\n",
       " array(195120.1, dtype=float32),\n",
       " array(195042.31, dtype=float32),\n",
       " array(194978.83, dtype=float32),\n",
       " array(195083.73, dtype=float32),\n",
       " array(194948.72, dtype=float32),\n",
       " array(194937.3, dtype=float32),\n",
       " array(194868.69, dtype=float32),\n",
       " array(194839.9, dtype=float32),\n",
       " array(194942.06, dtype=float32),\n",
       " array(194817.9, dtype=float32),\n",
       " array(194856.77, dtype=float32),\n",
       " array(194795.58, dtype=float32),\n",
       " array(194820.97, dtype=float32),\n",
       " array(194794.67, dtype=float32),\n",
       " array(194783.94, dtype=float32),\n",
       " array(194737.89, dtype=float32),\n",
       " array(194718.92, dtype=float32),\n",
       " array(194688.28, dtype=float32),\n",
       " array(194733.17, dtype=float32),\n",
       " array(194666.53, dtype=float32),\n",
       " array(194732.05, dtype=float32),\n",
       " array(194686.53, dtype=float32),\n",
       " array(194709.11, dtype=float32),\n",
       " array(194679.67, dtype=float32),\n",
       " array(194514.11, dtype=float32),\n",
       " array(194555.11, dtype=float32),\n",
       " array(194636.56, dtype=float32),\n",
       " array(194522.38, dtype=float32),\n",
       " array(194471.89, dtype=float32),\n",
       " array(194444.05, dtype=float32),\n",
       " array(194536.2, dtype=float32),\n",
       " array(194507.75, dtype=float32),\n",
       " array(194428.81, dtype=float32),\n",
       " array(194301.12, dtype=float32),\n",
       " array(194474.25, dtype=float32),\n",
       " array(194423.55, dtype=float32),\n",
       " array(194293.36, dtype=float32),\n",
       " array(194278.73, dtype=float32),\n",
       " array(194292.45, dtype=float32),\n",
       " array(194335.62, dtype=float32),\n",
       " array(194251.22, dtype=float32),\n",
       " array(194226.12, dtype=float32),\n",
       " array(194297.98, dtype=float32),\n",
       " array(194213.69, dtype=float32),\n",
       " array(194199.27, dtype=float32),\n",
       " array(194193.17, dtype=float32),\n",
       " array(194167.67, dtype=float32),\n",
       " array(194119.84, dtype=float32),\n",
       " array(194036.17, dtype=float32),\n",
       " array(194151.3, dtype=float32),\n",
       " array(193961.27, dtype=float32),\n",
       " array(194075.39, dtype=float32),\n",
       " array(193999.88, dtype=float32),\n",
       " array(194025.55, dtype=float32),\n",
       " array(194044.86, dtype=float32),\n",
       " array(193904.34, dtype=float32),\n",
       " array(193918.62, dtype=float32),\n",
       " array(193831.12, dtype=float32),\n",
       " array(193827.48, dtype=float32),\n",
       " array(193875.22, dtype=float32),\n",
       " array(193861.56, dtype=float32),\n",
       " array(193894.66, dtype=float32),\n",
       " array(193794.14, dtype=float32),\n",
       " array(193774.9, dtype=float32),\n",
       " array(193748.12, dtype=float32),\n",
       " array(193678.52, dtype=float32),\n",
       " array(193739.28, dtype=float32),\n",
       " array(193681.48, dtype=float32),\n",
       " array(193698.98, dtype=float32),\n",
       " array(193600.48, dtype=float32),\n",
       " array(193582.11, dtype=float32),\n",
       " array(193666.77, dtype=float32),\n",
       " array(193611.53, dtype=float32),\n",
       " array(193581.53, dtype=float32),\n",
       " array(193582.73, dtype=float32),\n",
       " array(193634.77, dtype=float32),\n",
       " array(193472.7, dtype=float32),\n",
       " array(193479.23, dtype=float32),\n",
       " array(193444.08, dtype=float32),\n",
       " array(193439.52, dtype=float32),\n",
       " array(193419.64, dtype=float32),\n",
       " array(193366.9, dtype=float32),\n",
       " array(193292.16, dtype=float32),\n",
       " array(193345.38, dtype=float32),\n",
       " array(193417.53, dtype=float32),\n",
       " array(193347.86, dtype=float32),\n",
       " array(193282.11, dtype=float32),\n",
       " array(193224.52, dtype=float32),\n",
       " array(193223.19, dtype=float32),\n",
       " array(193229.95, dtype=float32),\n",
       " array(193239.7, dtype=float32),\n",
       " array(193160.06, dtype=float32),\n",
       " array(193178.34, dtype=float32),\n",
       " array(193166.39, dtype=float32),\n",
       " array(193146.02, dtype=float32),\n",
       " array(193124.3, dtype=float32),\n",
       " array(193107.97, dtype=float32),\n",
       " array(193059.16, dtype=float32),\n",
       " array(193062.33, dtype=float32),\n",
       " array(192966.53, dtype=float32),\n",
       " array(192985.89, dtype=float32),\n",
       " array(192997.27, dtype=float32),\n",
       " array(192948.47, dtype=float32),\n",
       " array(192987.4, dtype=float32),\n",
       " array(192834.88, dtype=float32),\n",
       " array(192890.72, dtype=float32),\n",
       " array(192850.31, dtype=float32),\n",
       " array(192778.53, dtype=float32),\n",
       " array(192893.06, dtype=float32),\n",
       " array(192828.23, dtype=float32),\n",
       " array(192789.67, dtype=float32),\n",
       " array(192679.62, dtype=float32),\n",
       " array(192790.22, dtype=float32),\n",
       " array(192692.42, dtype=float32),\n",
       " array(192712.03, dtype=float32),\n",
       " array(192665.98, dtype=float32),\n",
       " array(192669.3, dtype=float32),\n",
       " array(192494.48, dtype=float32),\n",
       " array(192618.7, dtype=float32),\n",
       " array(192644.92, dtype=float32),\n",
       " array(192594.12, dtype=float32),\n",
       " array(192453.25, dtype=float32),\n",
       " array(192543.94, dtype=float32),\n",
       " array(192523.1, dtype=float32),\n",
       " array(192434.58, dtype=float32),\n",
       " array(192394.17, dtype=float32),\n",
       " array(192400.61, dtype=float32),\n",
       " array(192294.95, dtype=float32),\n",
       " array(192311.23, dtype=float32),\n",
       " array(192364.2, dtype=float32),\n",
       " array(192260.94, dtype=float32),\n",
       " array(192342.25, dtype=float32),\n",
       " array(192373.05, dtype=float32),\n",
       " array(192289.72, dtype=float32),\n",
       " array(192252.1, dtype=float32),\n",
       " array(192175.5, dtype=float32),\n",
       " array(192125.38, dtype=float32),\n",
       " array(192207.11, dtype=float32),\n",
       " array(192208.77, dtype=float32),\n",
       " array(192209.06, dtype=float32),\n",
       " array(192199.6, dtype=float32),\n",
       " array(192092.25, dtype=float32),\n",
       " array(192022.44, dtype=float32),\n",
       " array(192062.97, dtype=float32),\n",
       " array(192010.45, dtype=float32),\n",
       " array(191954.62, dtype=float32),\n",
       " array(191973.48, dtype=float32),\n",
       " array(191971.17, dtype=float32),\n",
       " array(191911.5, dtype=float32),\n",
       " array(191886., dtype=float32),\n",
       " array(191939.81, dtype=float32),\n",
       " array(191901.58, dtype=float32),\n",
       " array(191774.38, dtype=float32),\n",
       " array(191832.39, dtype=float32),\n",
       " array(191788.8, dtype=float32),\n",
       " array(191754.89, dtype=float32),\n",
       " array(191635.83, dtype=float32),\n",
       " array(191624.17, dtype=float32),\n",
       " array(191689.4, dtype=float32),\n",
       " array(191641.72, dtype=float32),\n",
       " array(191635.34, dtype=float32),\n",
       " array(191607.56, dtype=float32),\n",
       " array(191670.47, dtype=float32),\n",
       " array(191608.9, dtype=float32),\n",
       " array(191633.97, dtype=float32),\n",
       " array(191576.3, dtype=float32),\n",
       " array(191453.17, dtype=float32),\n",
       " array(191489.66, dtype=float32),\n",
       " array(191444.38, dtype=float32),\n",
       " array(191455.81, dtype=float32),\n",
       " array(191395.61, dtype=float32),\n",
       " array(191498.81, dtype=float32),\n",
       " array(191396.62, dtype=float32),\n",
       " array(191270.25, dtype=float32),\n",
       " array(191268.08, dtype=float32),\n",
       " array(191329.5, dtype=float32),\n",
       " array(191286.45, dtype=float32),\n",
       " array(191245.3, dtype=float32),\n",
       " array(191164.5, dtype=float32),\n",
       " array(191188.73, dtype=float32),\n",
       " array(191273.33, dtype=float32),\n",
       " array(191201.17, dtype=float32),\n",
       " array(191154.16, dtype=float32),\n",
       " array(191080.25, dtype=float32),\n",
       " array(191268.19, dtype=float32),\n",
       " array(191130.72, dtype=float32),\n",
       " array(191011.61, dtype=float32),\n",
       " array(191055.81, dtype=float32),\n",
       " array(190836.78, dtype=float32),\n",
       " array(190943.42, dtype=float32),\n",
       " array(190990.95, dtype=float32),\n",
       " array(190831.2, dtype=float32),\n",
       " array(190941.62, dtype=float32),\n",
       " array(190876.92, dtype=float32),\n",
       " array(190815.56, dtype=float32),\n",
       " array(190776.31, dtype=float32),\n",
       " array(190801.81, dtype=float32),\n",
       " array(190739.4, dtype=float32),\n",
       " array(190590.92, dtype=float32),\n",
       " array(190756.4, dtype=float32),\n",
       " array(190778.19, dtype=float32),\n",
       " array(190690.55, dtype=float32),\n",
       " array(190553.75, dtype=float32),\n",
       " array(190535.75, dtype=float32),\n",
       " array(190706.5, dtype=float32),\n",
       " array(190701.28, dtype=float32),\n",
       " array(190548.03, dtype=float32),\n",
       " array(190472.17, dtype=float32),\n",
       " array(190568.19, dtype=float32),\n",
       " array(190343.23, dtype=float32),\n",
       " array(190509.88, dtype=float32),\n",
       " array(190489.28, dtype=float32),\n",
       " array(190476.36, dtype=float32),\n",
       " array(190306.44, dtype=float32),\n",
       " array(190373.53, dtype=float32),\n",
       " array(190338.12, dtype=float32),\n",
       " array(190276.2, dtype=float32),\n",
       " array(190286.97, dtype=float32),\n",
       " array(190128.77, dtype=float32),\n",
       " array(190307.67, dtype=float32),\n",
       " array(190221.14, dtype=float32),\n",
       " array(190135.02, dtype=float32),\n",
       " array(190166.2, dtype=float32),\n",
       " array(190123.9, dtype=float32),\n",
       " array(190118.23, dtype=float32),\n",
       " array(190033.67, dtype=float32),\n",
       " array(190069.22, dtype=float32),\n",
       " array(189873.1, dtype=float32),\n",
       " array(190062.19, dtype=float32),\n",
       " array(189915.34, dtype=float32),\n",
       " array(190206.78, dtype=float32),\n",
       " array(189833.42, dtype=float32),\n",
       " array(189727.28, dtype=float32),\n",
       " array(189903.58, dtype=float32),\n",
       " array(189689.36, dtype=float32),\n",
       " array(189581.62, dtype=float32),\n",
       " array(189779., dtype=float32),\n",
       " array(189751.2, dtype=float32),\n",
       " array(189808.72, dtype=float32),\n",
       " array(189589.19, dtype=float32),\n",
       " array(189570.34, dtype=float32),\n",
       " array(189609.77, dtype=float32),\n",
       " array(189543.69, dtype=float32),\n",
       " array(189600.94, dtype=float32),\n",
       " array(189620., dtype=float32),\n",
       " array(189564.47, dtype=float32),\n",
       " array(189482.47, dtype=float32),\n",
       " array(189657.39, dtype=float32),\n",
       " array(189513.84, dtype=float32),\n",
       " array(189479.39, dtype=float32),\n",
       " array(189315.6, dtype=float32),\n",
       " array(189431.17, dtype=float32),\n",
       " array(189385.66, dtype=float32),\n",
       " array(189279.73, dtype=float32),\n",
       " array(189222.25, dtype=float32),\n",
       " array(189341.67, dtype=float32),\n",
       " array(189340.4, dtype=float32),\n",
       " array(189290.44, dtype=float32),\n",
       " array(189006.44, dtype=float32),\n",
       " array(189245.48, dtype=float32),\n",
       " array(189082.72, dtype=float32),\n",
       " array(189026.33, dtype=float32),\n",
       " array(189106.05, dtype=float32),\n",
       " array(188980.31, dtype=float32),\n",
       " array(189067.92, dtype=float32),\n",
       " array(188852.83, dtype=float32),\n",
       " array(189006.3, dtype=float32),\n",
       " array(188938.55, dtype=float32),\n",
       " array(188908.61, dtype=float32),\n",
       " array(188852.84, dtype=float32),\n",
       " array(188839.27, dtype=float32),\n",
       " array(188853.22, dtype=float32),\n",
       " array(188877.53, dtype=float32),\n",
       " array(188973.33, dtype=float32),\n",
       " array(188901.62, dtype=float32),\n",
       " array(188759.97, dtype=float32),\n",
       " array(188658.47, dtype=float32),\n",
       " array(188830.06, dtype=float32),\n",
       " array(188676.27, dtype=float32),\n",
       " array(188642.78, dtype=float32),\n",
       " array(188607.05, dtype=float32),\n",
       " array(188584.67, dtype=float32),\n",
       " array(188532.77, dtype=float32),\n",
       " array(188591.53, dtype=float32),\n",
       " array(188546.95, dtype=float32),\n",
       " array(188343.38, dtype=float32),\n",
       " array(188460.42, dtype=float32),\n",
       " array(188383.67, dtype=float32),\n",
       " array(188377.86, dtype=float32),\n",
       " array(188409.9, dtype=float32),\n",
       " array(188509.39, dtype=float32),\n",
       " array(188334.78, dtype=float32),\n",
       " array(188199.23, dtype=float32),\n",
       " array(188245.11, dtype=float32),\n",
       " array(188376.33, dtype=float32),\n",
       " array(188184.05, dtype=float32),\n",
       " array(188009.2, dtype=float32),\n",
       " array(188172.22, dtype=float32),\n",
       " array(187992.34, dtype=float32),\n",
       " array(187974.45, dtype=float32),\n",
       " array(188307.86, dtype=float32),\n",
       " array(188100.19, dtype=float32),\n",
       " array(188043.17, dtype=float32),\n",
       " array(188108.69, dtype=float32),\n",
       " array(188012.16, dtype=float32),\n",
       " array(187945.19, dtype=float32),\n",
       " array(187803.89, dtype=float32),\n",
       " array(187893.53, dtype=float32),\n",
       " array(187731.95, dtype=float32),\n",
       " array(187858.73, dtype=float32),\n",
       " array(187774.53, dtype=float32),\n",
       " array(187549.52, dtype=float32),\n",
       " array(187808.44, dtype=float32),\n",
       " array(187910.97, dtype=float32),\n",
       " array(187696.44, dtype=float32),\n",
       " array(187682.72, dtype=float32),\n",
       " array(187538.66, dtype=float32),\n",
       " array(187490.48, dtype=float32),\n",
       " array(187569.05, dtype=float32),\n",
       " array(187544.97, dtype=float32),\n",
       " array(187541.17, dtype=float32),\n",
       " array(187372.61, dtype=float32),\n",
       " array(187336.56, dtype=float32),\n",
       " array(187587.84, dtype=float32),\n",
       " array(187402.02, dtype=float32),\n",
       " array(187258.4, dtype=float32),\n",
       " array(187423.8, dtype=float32),\n",
       " array(187432.52, dtype=float32),\n",
       " array(187294.84, dtype=float32),\n",
       " array(187121.72, dtype=float32),\n",
       " array(187257.78, dtype=float32),\n",
       " array(187166.78, dtype=float32),\n",
       " array(187261.1, dtype=float32),\n",
       " array(187119.12, dtype=float32),\n",
       " array(187199.03, dtype=float32),\n",
       " array(186952.78, dtype=float32),\n",
       " array(187122.73, dtype=float32),\n",
       " array(187237.62, dtype=float32),\n",
       " array(187062.22, dtype=float32),\n",
       " array(187013.95, dtype=float32),\n",
       " array(186993.69, dtype=float32),\n",
       " array(186934.17, dtype=float32),\n",
       " array(186798.67, dtype=float32),\n",
       " array(186702.38, dtype=float32),\n",
       " array(186861.97, dtype=float32),\n",
       " array(186794.97, dtype=float32),\n",
       " array(186723.62, dtype=float32),\n",
       " array(186800.08, dtype=float32),\n",
       " array(186631.14, dtype=float32),\n",
       " array(186753.95, dtype=float32),\n",
       " array(186822.38, dtype=float32),\n",
       " array(186906.1, dtype=float32),\n",
       " array(186677.14, dtype=float32),\n",
       " array(186591.67, dtype=float32),\n",
       " array(186518.81, dtype=float32),\n",
       " array(186579.52, dtype=float32),\n",
       " array(186455.03, dtype=float32),\n",
       " array(186372.28, dtype=float32),\n",
       " array(186301.39, dtype=float32),\n",
       " array(186342.28, dtype=float32),\n",
       " array(186210.8, dtype=float32),\n",
       " array(186393.34, dtype=float32),\n",
       " array(186535.66, dtype=float32),\n",
       " array(186315.33, dtype=float32),\n",
       " array(186249.8, dtype=float32),\n",
       " array(186138.4, dtype=float32),\n",
       " array(186309.44, dtype=float32),\n",
       " array(186154.16, dtype=float32),\n",
       " array(186129.36, dtype=float32),\n",
       " array(186107.34, dtype=float32),\n",
       " array(185899.55, dtype=float32),\n",
       " array(185928.08, dtype=float32),\n",
       " array(185923.81, dtype=float32),\n",
       " array(185794.4, dtype=float32),\n",
       " array(186091.1, dtype=float32),\n",
       " array(185900.8, dtype=float32),\n",
       " array(186037.39, dtype=float32),\n",
       " array(185955.06, dtype=float32),\n",
       " array(185886.94, dtype=float32),\n",
       " array(185839.5, dtype=float32),\n",
       " array(185884.92, dtype=float32),\n",
       " array(185769.62, dtype=float32),\n",
       " array(185680.61, dtype=float32),\n",
       " array(185602.53, dtype=float32),\n",
       " array(185735.05, dtype=float32),\n",
       " array(185531.25, dtype=float32),\n",
       " array(185580.72, dtype=float32),\n",
       " array(185642.81, dtype=float32),\n",
       " array(185512.98, dtype=float32),\n",
       " array(185562.38, dtype=float32),\n",
       " array(185293.11, dtype=float32),\n",
       " array(185407.67, dtype=float32),\n",
       " array(185395.12, dtype=float32),\n",
       " array(185427.64, dtype=float32),\n",
       " array(185481.5, dtype=float32),\n",
       " array(185263.34, dtype=float32),\n",
       " array(185472.92, dtype=float32),\n",
       " array(185298.52, dtype=float32),\n",
       " array(185440.4, dtype=float32),\n",
       " array(185355.16, dtype=float32),\n",
       " array(185319.27, dtype=float32),\n",
       " array(185066.86, dtype=float32),\n",
       " array(185074.23, dtype=float32),\n",
       " array(185161.42, dtype=float32),\n",
       " array(185157.61, dtype=float32),\n",
       " array(184945., dtype=float32),\n",
       " array(185157.95, dtype=float32),\n",
       " array(185071.5, dtype=float32),\n",
       " array(184919.05, dtype=float32),\n",
       " array(184881.17, dtype=float32),\n",
       " array(184949.64, dtype=float32),\n",
       " array(185046.42, dtype=float32),\n",
       " array(184993.48, dtype=float32),\n",
       " array(184925.77, dtype=float32),\n",
       " array(184784.16, dtype=float32),\n",
       " array(184671.66, dtype=float32),\n",
       " array(184792.67, dtype=float32),\n",
       " array(184808.23, dtype=float32),\n",
       " array(184613.11, dtype=float32),\n",
       " array(184531.5, dtype=float32),\n",
       " array(184541.48, dtype=float32),\n",
       " array(184457.19, dtype=float32),\n",
       " array(184623.84, dtype=float32),\n",
       " array(184473.61, dtype=float32),\n",
       " array(184597.7, dtype=float32),\n",
       " array(184753.38, dtype=float32),\n",
       " array(184536.48, dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting the final_losses into the numpy for proper graphical\n",
    "### Representation using matplotlib (using tensors withoout any conversion\n",
    "### causes an error\n",
    "\n",
    "final_losses_numpy = []\n",
    "for i in final_losses:\n",
    "    final_losses_numpy.append(i.detach().numpy())\n",
    "final_losses_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "507a96eb-c377-4488-88fb-ac6fb5a94ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs), final_losses_numpy)\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77b616ac-a495-42f6-9552-4ad49df2c224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 53213.99609375\n"
     ]
    }
   ],
   "source": [
    "#### Validate the Test Data\n",
    "y_pred=\"\"\n",
    "with torch.no_grad():\n",
    "    y_pred=model(test_categorical,test_cont)\n",
    "    loss=torch.sqrt(loss_function(y_pred,y_test))\n",
    "print('RMSE: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f04a53f2-f0f4-4a07-b969-69f0b8cd2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verify=pd.DataFrame(y_test.tolist(),columns=[\"Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87841f7f-966d-424d-98dd-f4b4d6715c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted=pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c9c0853-80c5-4e84-876b-649c625fef95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113246.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188545.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146020.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218163.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207466.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202523.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150986.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>307970.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>157131.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>369699.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>224311.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>199738.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>179171.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104793.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>195084.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105558.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>246234.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>117428.710938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>297816.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75902.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>190329.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>110580.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>97607.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>181802.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>196248.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>190261.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>139630.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>355165.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>137301.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>172441.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>82978.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>119184.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>254542.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>45581.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>237163.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>196055.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>128397.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>128565.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>153956.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>111852.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>261876.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>307536.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>83194.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>148345.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>185641.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>105397.585938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>103308.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>149994.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>169367.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>671951.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>127473.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>338965.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>227268.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>143458.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>252442.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>195125.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>141751.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>128082.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>271383.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>180119.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>314615.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>106747.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>212469.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>225240.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>173354.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>123760.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>180566.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>251923.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>62953.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>258093.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>76494.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>76332.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>96144.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>270102.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>192940.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>219659.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>133110.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>116453.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>119151.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>111331.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>147859.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>130147.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>91645.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>251614.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>129234.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>112294.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>158921.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>139370.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>141917.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>101369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>275432.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>132075.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>141866.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>131252.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>128195.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>341177.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>218811.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>339473.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>247951.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>261176.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>169354.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>162620.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>224665.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109251.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>218854.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>150191.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>161774.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>247009.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>267953.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>244348.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>103439.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>127121.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>60274.457031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>189980.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>108264.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>160016.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>127313.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109300.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>347991.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>271068.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>227330.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>99657.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>182902.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>126658.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>104740.742188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>132041.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>206371.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>302411.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>107492.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>154574.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>116481.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>103077.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>194284.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>171163.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>248298.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>111933.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>271291.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>132465.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>136895.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>236740.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>240274.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>145994.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>71661.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>297770.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>151492.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>274763.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>150335.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>140809.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>139631.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>129214.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>124723.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>132610.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>212939.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>126487.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>95109.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>208504.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>100444.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>195600.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>162031.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>169288.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>115006.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>321733.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>139777.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>189172.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>204574.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>354598.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>226144.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>96383.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>262906.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>124251.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>89718.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>99458.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>291841.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>94143.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>164854.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>167559.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>170309.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>259097.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>223068.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>117320.468750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prediction\n",
       "0    113246.789062\n",
       "1    188545.296875\n",
       "2    146020.171875\n",
       "3    218163.765625\n",
       "4    207466.531250\n",
       "5    202523.921875\n",
       "6    150986.687500\n",
       "7    307970.125000\n",
       "8    157131.218750\n",
       "9    369699.031250\n",
       "10   224311.546875\n",
       "11   199738.390625\n",
       "12   179171.656250\n",
       "13   104793.695312\n",
       "14   195084.062500\n",
       "15   105558.132812\n",
       "16   246234.796875\n",
       "17   117428.710938\n",
       "18   297816.875000\n",
       "19    75902.601562\n",
       "20   190329.562500\n",
       "21   110580.070312\n",
       "22    97607.171875\n",
       "23   181802.265625\n",
       "24   196248.453125\n",
       "25   190261.843750\n",
       "26   139630.531250\n",
       "27   355165.281250\n",
       "28   137301.234375\n",
       "29   172441.203125\n",
       "30    82978.148438\n",
       "31   119184.882812\n",
       "32   254542.218750\n",
       "33    45581.203125\n",
       "34   237163.406250\n",
       "35   196055.140625\n",
       "36   128397.195312\n",
       "37   128565.281250\n",
       "38   153956.390625\n",
       "39   111852.257812\n",
       "40   261876.765625\n",
       "41   307536.156250\n",
       "42    83194.273438\n",
       "43   148345.390625\n",
       "44   185641.875000\n",
       "45   105397.585938\n",
       "46   103308.039062\n",
       "47   149994.046875\n",
       "48   169367.328125\n",
       "49   671951.687500\n",
       "50   127473.828125\n",
       "51   338965.093750\n",
       "52   227268.109375\n",
       "53   143458.109375\n",
       "54   252442.296875\n",
       "55   195125.671875\n",
       "56   141751.421875\n",
       "57   128082.437500\n",
       "58   271383.218750\n",
       "59   180119.390625\n",
       "60   314615.687500\n",
       "61   106747.500000\n",
       "62   212469.609375\n",
       "63   225240.484375\n",
       "64   173354.812500\n",
       "65   123760.156250\n",
       "66   180566.921875\n",
       "67   251923.781250\n",
       "68    62953.988281\n",
       "69   258093.750000\n",
       "70    76494.656250\n",
       "71    76332.007812\n",
       "72    96144.273438\n",
       "73   270102.500000\n",
       "74   192940.312500\n",
       "75   219659.234375\n",
       "76   133110.640625\n",
       "77   116453.648438\n",
       "78   119151.765625\n",
       "79   111331.789062\n",
       "80   147859.078125\n",
       "81   130147.773438\n",
       "82    91645.914062\n",
       "83   251614.156250\n",
       "84   129234.781250\n",
       "85   112294.125000\n",
       "86   158921.921875\n",
       "87   139370.140625\n",
       "88   141917.531250\n",
       "89   101369.000000\n",
       "90   275432.281250\n",
       "91   132075.640625\n",
       "92   141866.671875\n",
       "93   131252.984375\n",
       "94   128195.156250\n",
       "95   341177.062500\n",
       "96   218811.265625\n",
       "97   339473.156250\n",
       "98   247951.359375\n",
       "99   261176.890625\n",
       "100  169354.828125\n",
       "101  162620.812500\n",
       "102  224665.546875\n",
       "103  109251.484375\n",
       "104  218854.828125\n",
       "105  150191.453125\n",
       "106  161774.921875\n",
       "107  247009.234375\n",
       "108  267953.343750\n",
       "109  244348.578125\n",
       "110  103439.906250\n",
       "111  127121.789062\n",
       "112   60274.457031\n",
       "113  189980.750000\n",
       "114  108264.734375\n",
       "115  160016.437500\n",
       "116  127313.312500\n",
       "117  109300.437500\n",
       "118  347991.812500\n",
       "119  271068.531250\n",
       "120  227330.515625\n",
       "121   99657.117188\n",
       "122  182902.359375\n",
       "123  126658.460938\n",
       "124  104740.742188\n",
       "125  132041.578125\n",
       "126  206371.281250\n",
       "127  302411.781250\n",
       "128  107492.937500\n",
       "129  154574.515625\n",
       "130  116481.226562\n",
       "131  103077.937500\n",
       "132  194284.453125\n",
       "133  171163.750000\n",
       "134  248298.671875\n",
       "135  111933.554688\n",
       "136  271291.843750\n",
       "137  132465.812500\n",
       "138  136895.093750\n",
       "139  236740.250000\n",
       "140  240274.093750\n",
       "141  145994.578125\n",
       "142   71661.328125\n",
       "143  297770.468750\n",
       "144  151492.015625\n",
       "145  274763.156250\n",
       "146  150335.421875\n",
       "147  140809.468750\n",
       "148  139631.515625\n",
       "149  129214.765625\n",
       "150  124723.117188\n",
       "151  132610.046875\n",
       "152  212939.234375\n",
       "153  126487.132812\n",
       "154   95109.195312\n",
       "155  208504.015625\n",
       "156  100444.257812\n",
       "157  195600.546875\n",
       "158  162031.515625\n",
       "159  169288.390625\n",
       "160  115006.351562\n",
       "161  321733.062500\n",
       "162  139777.109375\n",
       "163  189172.546875\n",
       "164  204574.234375\n",
       "165  354598.625000\n",
       "166  226144.421875\n",
       "167   96383.164062\n",
       "168  262906.718750\n",
       "169  124251.867188\n",
       "170   89718.914062\n",
       "171   99458.828125\n",
       "172  291841.531250\n",
       "173   94143.359375\n",
       "174  164854.859375\n",
       "175  167559.578125\n",
       "176  170309.140625\n",
       "177  259097.078125\n",
       "178  223068.968750\n",
       "179  117320.468750"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb4712aa-254e-46c6-9128-b3e65f629b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>113246.789062</td>\n",
       "      <td>16753.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138887.0</td>\n",
       "      <td>188545.296875</td>\n",
       "      <td>-49658.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>146020.171875</td>\n",
       "      <td>29479.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195000.0</td>\n",
       "      <td>218163.765625</td>\n",
       "      <td>-23163.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142500.0</td>\n",
       "      <td>207466.531250</td>\n",
       "      <td>-64966.531250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test     Prediction    Difference\n",
       "0  130000.0  113246.789062  16753.210938\n",
       "1  138887.0  188545.296875 -49658.296875\n",
       "2  175500.0  146020.171875  29479.828125\n",
       "3  195000.0  218163.765625 -23163.765625\n",
       "4  142500.0  207466.531250 -64966.531250"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output=pd.concat([data_verify,data_predicted],axis=1)\n",
    "final_output['Difference']=final_output['Test']-final_output['Prediction']\n",
    "final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cfe9dae-e3ba-47e0-8ee4-2c59000776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the model\n",
    "torch.save(model,'HousePrice.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3361e489-95ed-4702-9a08-d1fc5e65e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving using state_dict which helps to save the weights of the model\n",
    "torch.save(model.state_dict(),'HouseWeights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cab910a-bb6d-4ab5-8ddd-dc6ca0a4e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the saved Model\n",
    "embs_size=[(15, 8), (5, 3), (2, 1), (4, 2)] #required for loading\n",
    "model1=FeedForwardNN(embs_size,5,1,[100,50],p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "748b4a38-df52-4cc4-a8f0-5e9064003238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('HouseWeights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09fbe7bd-b265-4624-be17-ab76059e1110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e838b-2023-48d3-b08a-23355fb513dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
